Die Differential- bzw. Differenzialrechnung ist ein wesentlicher Bestandteil der Analysis und damit ein Gebiet der Mathematik. Sie ist eng verwandt mit der Integralrechnung, mit der sie gemeinsam unter der Bezeichnung Infinitesimalrechnung zusammengefasst wird. Zentrales Thema der Differentialrechnung ist die Berechnung lokaler Veränderungen von Funktionen.
Hierzu dienlich und gleichzeitig Grundbegriff der Differentialrechnung ist die Ableitung einer Funktion (auch Differentialquotient genannt), deren geometrische Entsprechung die Tangentensteigung ist. Die Ableitung ist (nach der Vorstellung von Leibniz) der Proportionalitätsfaktor zwischen verschwindend kleinen (infinitesimalen) Änderungen des Eingabewertes und den daraus resultierenden, ebenfalls infinitesimalen Änderungen des Funktionswertes. Existiert ein solcher Proportionalitätsfaktor, so nennt man die Funktion differenzierbar. Äquivalent wird die Ableitung in einem Punkt als diejenige lineare Abbildung definiert, die unter allen linearen Abbildungen die Änderung der Funktion lokal am besten approximiert. Entsprechend wird die Ableitung auch die Linearisierung der Funktion genannt.
In vielen Fällen ist die Differentialrechnung ein unverzichtbares Hilfsmittel zur Bildung von mathematischen Modellen, welche die Wirklichkeit möglichst genau abbilden sollen, sowie zu deren nachfolgender Analyse. Die Entsprechung der Ableitung im untersuchten Sachverhalt ist häufig die momentane Änderungsrate; in den Wirtschaftswissenschaften spricht man auch häufig von Grenzraten (z. B. Grenzkosten, Grenzproduktivität eines Produktionsfaktors etc.).
Dieser Artikel erklärt außerdem die mathematischen Begriffe: Differenzenquotient, Differentialquotient, Differentiation, stetig differenzierbar, glatt, partielle Ableitung, totale Ableitung, Reduktion des Grades eines Polynoms.
In geometrischer Sprache ist die Ableitung eine verallgemeinerte Steigung. Der geometrische Begriff Steigung ist ursprünglich nur für lineare Funktionen definiert, deren Funktionsgraph eine Gerade ist. Die Ableitung einer beliebigen Funktion an einer Stelle definiert man als die Steigung der Tangente im Punkt des Graphen von .
In arithmetischer Sprache gibt die Ableitung einer Funktion für jedes an, wie groß der lineare Anteil der Änderung von ist (die Änderung 1. Ordnung), wenn sich um einen beliebig kleinen Betrag ändert. Für die exakte Formulierung dieses Sachverhalts wird der Begriff Grenzwert (oder Limes) verwendet.
In einer klassischen physikalischen Anwendung liefert die Ableitung der Orts- oder Weg-Zeit-Funktion nach der Zeit die Momentangeschwindigkeit eines Teilchens. Die Ableitung der Momentangeschwindigkeit nach der Zeit liefert die momentane Beschleunigung.


Die Aufgabenstellung der Differentialrechnung war als Tangentenproblem seit der Antike bekannt. Ein naheliegender Lösungsansatz bestand darin, die Tangente an eine Kurve durch ihre Sekante über einem endlichen (endlich heißt hier: größer als null), aber beliebig kleinen Intervall zu approximieren. Dabei war die technische Schwierigkeit zu überwinden, mit einer solchen infinitesimal kleinen Intervallbreite zu rechnen. Die ersten Anfänge der Differentialrechnung gehen auf Pierre de Fermat zurück. Er entwickelte um 1628 eine Methode, Extremstellen von algebraischen Termen zu bestimmen und Tangenten an Kegelschnitte und andere Kurven zu berechnen. Seine „Methode“ war rein algebraisch. Fermat betrachtete keine Grenzübergänge und schon gar keine Ableitungen. Gleichwohl lässt sich seine „Methode“ mit modernen Mitteln der Analysis interpretieren und rechtfertigen und hat Mathematiker wie Newton und Leibniz nachweislich inspiriert. Einige Jahre später wählte René Descartes einen anderen algebraischen Zugang, indem er an eine Kurve einen Kreis anlegte. Dieser schneidet die Kurve in zwei nahe beieinanderliegenden Punkten; es sei denn, er berührt die Kurve. Dieser Ansatz ermöglichte es ihm, für spezielle Kurven die Steigung der Tangente zu bestimmen.
Ende des 17. Jahrhunderts gelang es Isaac Newton und Gottfried Wilhelm Leibniz unabhängig voneinander, widerspruchsfrei funktionierende Kalküle zu entwickeln (zur Entdeckungsgeschichte und zum Prioritätsstreit siehe Geschichte der Infinitesimalrechnung). Newton ging das Problem jedoch von einer anderen Seite an als Leibniz. Während Newton das Problem physikalisch über das Momentangeschwindigkeitsproblem anging, gelang es Leibniz geometrisch über das Tangentenproblem. Ihre Arbeiten erlaubten das Abstrahieren von rein geometrischer Vorstellung und werden deshalb als Beginn der Analysis betrachtet. Bekannt wurden sie vor allem durch das Buch des Adligen Guillaume François Antoine, Marquis de L’Hospital, der bei Johann Bernoulli Privatunterricht nahm und dessen Forschung zur Analysis so publizierte. Die heute bekannten Ableitungsregeln basieren vor allem auf den Werken von Leonhard Euler, der den Funktionsbegriff prägte. Newton und Leibniz arbeiteten mit beliebig kleinen positiven Zahlen. Dies wurde bereits von Zeitgenossen als unlogisch kritisiert, beispielsweise von Bischof Berkeley in der polemischen Schrift The analyst; or, a discourse addressed to an infidel mathematician. Die Differentialrechnung wurde aber trotz herrschender Unsicherheit konsequent weiterentwickelt; in erster Linie wegen ihrer zahlreichen Anwendungen in der Physik und in anderen Gebieten der Mathematik. Symptomatisch für die damalige Zeit war das von der Preußischen Akademie der Wissenschaften 1784 veröffentlichte Preisausschreiben:
„… Die höhere Geometrie benutzt häufig unendlich große und unendlich kleine Größen; jedoch haben die alten Gelehrten das Unendliche sorgfältig vermieden, und einige berühmte Analysten unserer Zeit bekennen, dass die Wörter unendliche Größe widerspruchsvoll sind. Die Akademie verlangt also, dass man erkläre, wie aus einer widersprechenden Annahme so viele richtige Sätze entstanden sind, und dass man einen sicheren und klaren Grundbegriff angebe, welcher das Unendliche ersetzen dürfte, ohne die Rechnung zu schwierig oder zu lang zu machen …“[1]
Erst zum Anfang des 19. Jahrhunderts gelang es Augustin-Louis Cauchy, der Differentialrechnung die heute übliche logische Strenge zu geben, indem er von den infinitesimalen Größen abging und die Ableitung als Grenzwert von Sekantensteigungen (Differenzenquotienten) definierte. Die heute benutzte Definition des Grenzwerts wurde schließlich von Karl Weierstraß Ende des 19. Jahrhunderts formuliert.
Ausgangspunkt für die Definition der Ableitung ist die Näherung der Tangentensteigung durch eine Sekantensteigung (manchmal auch Sehnensteigung genannt). Gesucht sei die Steigung einer Funktion in einem Punkt . Man berechnet zunächst die Steigung der Sekante an über einem endlichen Intervall:
Die Sekantensteigung ist also der Quotient zweier Differenzen; sie wird deshalb auch Differenzenquotient genannt. Mit der Kurznotation für kann man die Sekantensteigung abgekürzt als schreiben.
Differenzenquotienten sind aus dem täglichen Leben wohlbekannt, zum Beispiel als Durchschnittsgeschwindigkeit:
Um eine Tangentensteigung (im genannten Anwendungsbeispiel also eine Momentangeschwindigkeit) zu berechnen, muss man die beiden Punkte, durch die die Sekante gezogen wird, immer weiter aneinander rücken. Dabei gehen sowohl als auch gegen Null. Der Quotient bleibt aber in vielen Fällen endlich. Auf diesem Grenzübergang beruht die folgende Definition:
Eine Funktion , die ein offenes Intervall U in die reellen Zahlen abbildet, heißt differenzierbar an der Stelle , falls der Grenzwert
existiert. Dieser Grenzwert heißt Differentialquotient oder Ableitung von nach an der Stelle und wird als
notiert. Gesprochen werden diese Notationen als „f Strich von x null“, „d f von x nach d x an der Stelle x gleich x null“, „d f nach d x von x null“ respektive „d nach d x von f von x null“. Im später folgenden Abschnitt Notationen werden noch weitere Varianten angeführt, um die Ableitung einer Funktion zu notieren.
Im Laufe der Zeit wurde folgende gleichwertige Definition gefunden, die sich im allgemeineren Kontext komplexer oder mehrdimensionaler Funktionen als leistungsfähiger erwiesen hat:
Eine Funktion heißt in einem Punkt differenzierbar, falls eine Konstante existiert, sodass
Der Zuwachs der Funktion , wenn man sich von nur wenig entfernt, etwa um den Wert , lässt sich also durch sehr gut approximieren, man nennt die lineare Funktion mit deswegen auch die Linearisierung von an der Stelle .
Eine weitere Definition ist: Es gibt eine an der Stelle stetige Funktion mit und eine Konstante , sodass für alle gilt
Die Bedingungen und dass an der Stelle stetig ist, bedeuten gerade, dass das „Restglied“ für gegen gegen konvergiert.
In beiden Fällen ist die Konstante eindeutig bestimmt und es gilt . Der Vorteil dieser Formulierung ist, dass Beweise einfacher zu führen sind, da kein Quotient betrachtet werden muss. Diese Darstellung der besten linearen Approximation wurde schon von Weierstraß, Henri Cartan und Jean Dieudonné konsequent angewandt.
Bezeichnet man eine Funktion als differenzierbar, ohne sich auf eine bestimmte Stelle zu beziehen, dann bedeutet dies die Differenzierbarkeit an jeder Stelle des Definitionsbereiches, also die Existenz einer eindeutigen Tangente für jeden Punkt des Graphen.
Jede differenzierbare Funktion ist stetig, die Umkehrung gilt jedoch nicht. Noch Anfang des 19. Jahrhunderts war man überzeugt, dass eine stetige Funktion höchstens an wenigen Stellen nicht differenzierbar sein könne (wie die Betragsfunktion). Bernard Bolzano konstruierte dann als erster Mathematiker tatsächlich eine Funktion, die überall stetig, aber nirgends differenzierbar ist, was in der Fachwelt allerdings nicht bekannt wurde; Karl Weierstraß fand dann in den 1860er Jahren ebenfalls eine derartige Funktion (siehe Weierstraß-Funktion), was diesmal unter Mathematikern Wellen schlug. Ein bekanntes mehrdimensionales Beispiel für eine stetige, nicht differenzierbare Funktion ist die von Helge von Koch 1904 vorgestellte Koch-Kurve.
Die Ableitung der Funktion an der Stelle bezeichnet mit , beschreibt lokal das Verhalten der Funktion in der Umgebung der betrachteten Stelle . Nun wird nicht die einzige Stelle sein, an der differenzierbar ist. Man kann daher versuchen, jeder Zahl aus dem Definitionsbereich von die Ableitung an dieser Stelle (also ) zuzuordnen. Auf diese Weise erhält man eine neue Funktion , deren Definitionsbereich die Menge aller Punkte ist, an denen differenzierbar ist. Diese Funktion heißt die Ableitungsfunktion oder kurz die Ableitung von und man sagt „ ist auf differenzierbar“.
Beispielsweise hat die Quadratfunktion an einer beliebigen Stelle die Ableitung die Quadratfunktion ist also auf der Menge der reellen Zahlen differenzierbar. Die zugehörige Ableitungsfunktion ist gegeben durch .
Die Ableitungsfunktion ist im Normalfall eine andere als die ursprüngliche, einzige Ausnahme sind die Vielfachen der Exponentialfunktion.
Ist die Ableitung stetig, dann heißt stetig differenzierbar. In Anlehnung an die Bezeichnung für die Gesamtheit (den Raum) der stetigen Funktionen mit Definitionsmenge wird der Raum der stetig differenzierbaren Funktionen mit abgekürzt.
Das Berechnen der Ableitung einer Funktion wird Differentiation oder Differenziation genannt; sprich, man differenziert diese Funktion.
Um die Ableitung elementarer Funktionen (z. B. , ,…) zu berechnen, hält man sich eng an die oben angegebene Definition, berechnet explizit einen Differenzenquotienten und lässt dann gegen Null gehen. In der Schulmathematik wird dies als „h-Methode“ bezeichnet. Der typische Mathematikanwender vollzieht diese Berechnung nur ein paar wenige Male in seinem Leben nach. Später kennt er die Ableitungen der wichtigsten elementaren Funktionen auswendig, schlägt Ableitungen nicht ganz so geläufiger Funktionen in einem Tabellenwerk (z. B. im Bronstein-Semendjajew oder unserer Tabelle von Ableitungs- und Stammfunktionen) nach und berechnet die Ableitung zusammengesetzter Funktionen mit Hilfe der Ableitungsregeln.
Gesucht sei die Ableitung von . Dann berechnet man den Differenzenquotienten als
und erhält im Limes die Ableitung der Funktion
ist an der Stelle 0 nicht differenzierbar:
Für alle gilt nämlich und damit
Für alle gilt dagegen und folglich
Da der links- und der rechtsseitige Grenzwert nicht übereinstimmen, existiert der Grenzwert nicht. Die Funktion ist somit an der betrachteten Stelle nicht differenzierbar. Die Differenzierbarkeit der Funktion an allen anderen Stellen ist dagegen noch immer gegeben.
Es existieren an der Stelle 0 jedoch die rechtsseitige Ableitung
und die linksseitige Ableitung
Betrachtet man den Graphen von , so kommt man zu der Erkenntnis, dass der Begriff der Differenzierbarkeit anschaulich bedeutet, dass der zugehörige Graph knickfrei verläuft.
Ein typisches Beispiel für nirgends differenzierbare stetige Funktionen, deren Existenz zunächst schwer vorstellbar erscheint, sind fast alle Pfade der brownschen Bewegung. Diese wird zum Beispiel zur Modellierung der Charts von Aktienkursen benutzt.
Eine Funktion heißt stetig differenzierbar, wenn ihre Ableitung stetig ist. Selbst wenn eine Funktion überall differenzierbar ist, muss die Ableitung nicht stetig sein. Zum Beispiel ist die Funktion
an jeder Stelle, inklusive , differenzierbar. Die Ableitung, die an der Stelle 0 über den Differenzenquotient bestimmt werden kann,
ist aber an der Stelle 0 nicht stetig.
Ableitungen zusammengesetzter Funktionen, z. B. oder , führt man mit Hilfe von Ableitungsregeln auf die Differentiation elementarer Funktionen zurück (siehe auch: Tabelle von Ableitungs- und Stammfunktionen).
Mit den folgenden Regeln kann man die Ableitung zusammengesetzter Funktionen auf Ableitungen einfacherer Funktionen zurückführen. Seien , und (im Definitionsbereich) differenzierbare, reelle Funktionen, und reelle Zahlen, dann gilt:
Die wesentliche Leistung Leibniz war die Erkenntnis, dass Integration und Differentiation zusammenhängen. Diese formulierte er im Hauptsatz der Differential- und Integralrechnung, auch Fundamentalsatz der Analysis genannt. Er besagt:
Ist ein Intervall, eine stetige Funktion und ein beliebiger Punkt, so ist die Funktion
stetig differenzierbar, und ihre Ableitung ist gleich .
Hiermit ist also eine Anleitung zum Integrieren gegeben: Gesucht ist eine Funktion , deren Ableitung der Integrand ist. Dann gilt:
Ein weiterer zentraler Satz der Differentialrechnung ist der Mittelwertsatz, der von Cauchy bewiesen wurde.
Es sei eine Funktion, die auf dem abgeschlossenen Intervall (mit ) definiert und stetig ist. Außerdem sei die Funktion im offenen Intervall differenzierbar. Unter diesen Voraussetzungen gibt es mindestens ein , sodass
gilt.
Ist die Ableitung einer Funktion wiederum differenzierbar, so lässt sich die zweite Ableitung von als Ableitung der ersten definieren. Auf dieselbe Weise können dann auch dritte, vierte etc. Ableitungen definiert werden. Eine Funktion kann dementsprechend einfach differenzierbar, zweifach differenzierbar etc. sein.
Die zweite Ableitung hat zahlreiche physikalische Anwendungen. Zum Beispiel ist die erste Ableitung des Orts nach der Zeit die Momentangeschwindigkeit, die zweite Ableitung die Beschleunigung. Aus der Physik kommt die Schreibweise , (Sprich: Punkt von t), für Ableitungen einer beliebigen Funktion nach der Zeit.
Wenn Politiker sich über den „Rückgang des Anstiegs der Arbeitslosenzahl“ äußern, dann sprechen sie von der zweiten Ableitung (Änderung des Anstiegs), um die Aussage der ersten Ableitung (Anstieg der Arbeitslosenzahl) zu relativieren.
Mehrfache Ableitungen können auf drei verschiedene Weisen geschrieben werden:
oder im physikalischen Fall (bei einer Ableitung nach der Zeit)
Für die formale Bezeichnung beliebiger Ableitungen legt man außerdem und fest.
Geschichtlich bedingt gibt es unterschiedliche Notationen, um die Ableitung einer Funktion darzustellen. In diesem Artikel wurde bisher hauptsächlich die Notation für die Ableitung von verwendet. Diese Notation geht auf den Mathematiker Joseph-Louis Lagrange zurück, der sie 1797 einführte.[2] Mit dieser Notation wird die zweite Ableitung von mit und die -te Ableitung mittels notiert.
Isaac Newton - neben Leibniz der Begründer der Differentialrechnung - notierte die erste Ableitung von mit , entsprechend notierte er die zweite Ableitung durch . Heutzutage wird diese Schreibweise hauptsächlich in der Physik, insbesondere in der Mechanik, für die Ableitung nach der Zeit verwendet.
Gottfried Wilhelm Leibniz führt für die erste Ableitung von (nach der Variablen ) die Notation ein. Hierbei handelt es sich nicht um einen Bruch. Gelesen wird das Symbol als „d f von x nach d x“. Für die zweite Ableitung notierte Leibniz und die -te Ableitung wird mittels notiert. Die Symbole und werden als Differentiale bezeichnet, haben aber in der modernen Differentialrechnung (abgesehen von der Theorie der Differentialformen) lediglich eine symbolische Bedeutung und sind nur in dieser Schreibweise als formaler Differentialquotient erlaubt. In manchen Anwendungen (Kettenregel, Integration mancher Differentialgleichungen, Integration durch Substitution) rechnet man mit ihnen aber fast so als seien sie gewöhnliche Variablen.
Die Notation oder für die erste Ableitung von geht auf Leonhard Euler zurück. In dieser Notation wird die zweite Ableitung durch oder und die -te Ableitung durch oder geschrieben.
Eine der wichtigsten Anwendungen der Differentialrechnung ist die Bestimmung von Extremwerten, meist zur Optimierung von Prozessen. Diese befinden sich unter anderem bei monotonen Funktionen am Rand des Definitionsbereichs, im Allgemeinen jedoch an den Stellen, wo die Ableitung Null ist. Eine Funktion kann einen Maximal- oder Minimalwert haben, ohne dass die Ableitung an dieser Stelle existiert, im Folgenden werden jedoch nur zumindest lokal differenzierbare Funktionen betrachtet. Als Beispiel nehmen wir die Polynomfunktion mit dem Funktionsterm
Die Abbildung zeigt den Verlauf der Graphen von , und .
Besitzt eine Funktion mit in einem Punkt ihren größten Wert, gilt also für alle dieses Intervalls , und ist im Punkt differenzierbar, so kann die Ableitung dort nur gleich null sein: . Eine entsprechende Aussage gilt, falls in den kleinsten Wert annimmt.
Geometrische Deutung dieses Satzes von Fermat ist, dass der Graph der Funktion in lokalen Extrempunkten eine parallel zur -Achse verlaufende Tangente, auch waagerechte Tangente genannt, besitzt.
Es ist somit für differenzierbare Funktionen eine notwendige Bedingung für das Vorliegen einer Extremstelle, dass die Ableitung an der betreffenden Stelle den Wert 0 annimmt:
Umgekehrt kann daraus, dass die Ableitung an einer Stelle den Wert null hat, noch nicht auf eine Extremstelle geschlossen werden, es könnte auch beispielsweise ein Sattelpunkt vorliegen. Eine Liste verschiedener hinreichender Kriterien, deren Erfüllung sicher auf eine Extremstelle schließen lässt, findet sich im Artikel Extremwert. Diese benutzen meist die zweite oder noch höhere Ableitungen.
Im Beispiel ist
Daraus folgt, dass genau für und gilt. Die Funktionswerte an diesen Stellen sind und , d. h. die Kurve hat in den Punkten und waagerechte Tangenten, und nur in diesen.
Da die Folge
abwechselnd aus kleinen und großen Werten besteht, muss in diesem Bereich ein Hoch- und ein Tiefpunkt liegen. Nach dem Satz von Fermat hat die Kurve in diesen Punkten eine waagerechte Tangente, es kommen also nur die oben ermittelten Punkte in Frage: Also ist ein Hochpunkt und ein Tiefpunkt.
Mit Hilfe der Ableitungen lassen sich noch weitere Eigenschaften der Funktion analysieren, wie Wendepunkte, Sattelpunkt, Konvexität oder die oben schon angesprochene Monotonie. Die Durchführung dieser Untersuchungen ist Gegenstand der Kurvendiskussion.
Ist eine ()-mal stetig differenzierbare Funktion im Intervall , dann gilt für alle und aus die Darstellung der sogenannten Taylor-Formel:
mit dem -ten Taylorpolynom an der Entwicklungsstelle
und dem ()-ten Restglied
Eine beliebig oft differenzierbare Funktion wird glatte Funktion genannt. Da sie alle Ableitungen besitzt, kann die oben angegebene Taylor-Formel erweitert werden auf die Taylor-Reihe von mit Entwicklungspunkt
Es stellt sich allerdings heraus, dass die Existenz aller Ableitungen nicht ergibt, dass sich durch die Taylor-Reihe darstellen lässt. Anders ausgedrückt: Jede analytische Funktion ist glatt, aber nicht umgekehrt, wie das im Artikel Taylorreihe gegebene Beispiel einer nicht analytischen glatten Funktion zeigt.
Häufig findet man in mathematischen Betrachtungen den Begriff hinreichend glatt. Hiermit ist gemeint, dass die Funktion so oft differenzierbar ist, wie nötig um den aktuellen Gedankengang durchzuführen.
Eine weitere wichtige Anwendung der Differentialrechnung besteht in der mathematischen Modellierung physikalischer Vorgänge. Wachstum, Bewegung oder Kräfte haben alle mit Ableitungen zu tun, ihre formelhafte Beschreibung muss also Differentiale enthalten. Typischerweise führt dies auf Gleichungen, in denen Ableitungen einer unbekannten Funktion auftauchen, eben genau Differentialgleichungen.
Beispielsweise verknüpft das newtonsche Bewegungsgesetz
die Beschleunigung eines Körpers mit seiner Masse und der auf ihn einwirkenden Kraft . Das Grundproblem der Mechanik lautet deshalb, aus einer gegebenen Beschleunigung auf die Ortsfunktion eines Körpers zurückzuschließen. Diese Aufgabe, eine Umkehrung der zweifachen Differentiation, hat die mathematische Gestalt einer Differentialgleichung zweiter Ordnung. Die mathematische Schwierigkeit dieses Problems rührt daher, dass Ort, Geschwindigkeit und Beschleunigung Vektoren sind, die im Allgemeinen nicht in die gleiche Richtung zeigen, und dass die Kraft von der Zeit und vom Ort abhängen kann.
Da viele Modelle mehrdimensional sind, sind bei der Formulierung häufig die weiter unten erklärten partiellen Ableitungen sehr wichtig, mit denen sich partielle Differentialgleichungen formulieren lassen. Mathematisch kompakt werden diese mittels Differentialoperatoren beschrieben und analysiert.
In der Mikroökonomie werden beispielsweise verschiedene Arten von Produktionsfunktionen analysiert, um daraus Erkenntnisse für makroökonomische Zusammenhänge zu gewinnen. Hier ist vor allem das typische Verhalten einer Produktionsfunktion von Interesse: Wie reagiert die abhängige Variable Output (produzierte Menge eines Gutes), wenn der Input (Produktionsfaktor, z. B. Arbeit oder Kapital) um eine (infinitesimal) kleine Einheit erhöht wird?
Ein Grundtyp einer Produktionsfunktion ist etwa die neoklassische Produktionsfunktion. Sie zeichnet sich dadurch aus, dass der Output bei jedem zusätzlichen Input steigt, dass aber die Zuwächse abnehmend sind. Es sei beispielsweise für einen Betrieb die Produktionsfunktion
maßgebend. Die erste Ableitung dieser Funktion ergibt unter Anwendung der Kettenregel
Da der Wurzelausdruck der ersten Ableitung nur positiv werden kann, sieht man, dass der Ertrag bei jedem zusätzlichen Input steigt. Die zweite Ableitung ergibt
Sie wird für alle Inputs negativ, also fallen die Zuwachsraten. Man könnte also sagen, dass bei steigendem Input der Output unterproportional steigt. Die relative Änderung des Outputs im Verhältnis zu einer relativen Änderung des Inputs ist hier durch die Elastizität gegeben.
Neben der Bestimmung der Steigung von Funktionen ist die Differentialrechnung durch ihren Kalkül ein wesentliches Hilfsmittel bei der Termumformung. Hierbei löst man sich von jeglichem Zusammenhang mit der ursprünglichen Bedeutung der Ableitung als Anstieg. Hat man zwei Terme als gleich erkannt, lassen sich durch Differentiation daraus weitere (gesuchte) Identitäten gewinnen. Ein Beispiel mag dies verdeutlichen:
Aus der Teleskopsumme:
soll
möglichst einfach gewonnen werden. Dies gelingt durch Differentiation mit Hilfe der Quotientenregel:
Alternativ ergibt sich die Identität auch durch Ausmultiplizieren und anschließendes dreifaches Teleskopieren, was aber nicht so einfach zu durchschauen ist.
Bisher wurde nur von reellen Funktionen gesprochen. Für Differenzierbarkeit von Funktionen mit komplexen Argumenten wird einfach die Definition mit der Linearisierung verwandt. Hier ist die Bedingung viel einschränkender als im reellen: So ist beispielsweise die Betragsfunktion nirgendwo komplex differenzierbar. Gleichzeitig ist jede in einer Umgebung einmal komplex differenzierbare Funktion automatisch beliebig oft differenzierbar, es existieren also alle höheren Ableitungen.
Alle vorherigen Ausführungen legten eine Funktion in einer Variablen (also mit einer reellen oder komplexen Zahl als Argument) zugrunde. Funktionen, die Vektoren auf Vektoren oder Vektoren auf Zahlen abbilden, können ebenfalls eine Ableitung haben. Allerdings ist eine Tangente an den Funktionsgraph in diesen Fällen nicht mehr eindeutig bestimmt, da es viele verschiedene Richtungen gibt. Hier ist also eine Erweiterung des bisherigen Ableitungsbegriffs notwendig.
Wir betrachten zunächst eine Funktion, die von geht. Ein Beispiel ist die Temperaturfunktion: In Abhängigkeit vom Ort wird die Temperatur im Zimmer gemessen, um zu beurteilen, wie effektiv die Heizung ist. Wird das Thermometer in eine bestimmte Richtung bewegt, ist eine Veränderung der Temperatur festzustellen. Dies entspricht der so genannten Richtungsableitung. Die Richtungsableitungen in spezielle Richtungen, nämlich die der Koordinatenachsen, nennt man die partiellen Ableitungen.
Insgesamt lassen sich für eine Funktion in Variablen insgesamt partielle Ableitungen errechnen:
Die einzelnen partiellen Ableitungen einer Funktion lassen sich auch gebündelt als Gradient oder Nablavektor anschreiben. Partielle Ableitungen können wieder differenzierbar sein und ihre partiellen Ableitungen lassen sich dann in der so genannten Hesse-Matrix anordnen. Analog zum eindimensionalen Fall sind die Kandidaten für Extremstellen da, wo die Ableitung null ist, also der Gradient verschwindet. Ebenfalls analog bestimmt die zweite Ableitung, also die Hesse-Matrix, in gewissen Fällen den exakt vorliegenden Fall. Im Gegensatz zum eindimensionalen ist allerdings die Formenvielfalt in diesem Falle größer. Mittels einer Hauptachsentransformation der durch eine mehrdimensionale Taylor-Entwicklung im betrachteten Punkt gegebenen quadratischen Form lassen sich die verschiedenen Fälle klassifizieren.
Ist eine Funktion durch eine implizite Gleichung gegeben, so folgt aus der mehrdimensionalen Kettenregel, die für Funktionen mehrerer Variablen gilt
Für die Ableitung der Funktion ergibt sich daher
Eine Funktion , wobei eine offene Menge ist, heißt in einem Punkt total differenzierbar (oder auch nur differenzierbar), falls eine lineare Abbildung existiert, so dass
Für den eindimensionalen Fall stimmt diese Definition mit der oben angegebenen überein. Die lineare Abbildung ist bei Existenz eindeutig bestimmt, ist also insbesondere unabhängig von der Wahl äquivalenter Normen. Die Tangente wird also durch die lokale Linearisierung der Funktion abstrahiert. Die Matrixdarstellung der ersten Ableitung von nennt man Jacobi-Matrix. Es handelt sich um eine -Matrix. Für erhält man den oben beschriebenen Gradienten.
Zwischen den partiellen Ableitungen und der totalen Ableitung besteht folgender Zusammenhang: Existiert in einem Punkt die totale Ableitung, so existieren dort auch alle partiellen Ableitungen. In diesem Fall stimmen die partiellen Ableitungen mit den Koeffizienten der Jacobi-Matrix überein. Umgekehrt folgt aus der Existenz der partiellen Ableitungen in einem Punkt nicht zwingend die totale Differenzierbarkeit, ja nicht einmal die Stetigkeit. Sind die partiellen Ableitungen jedoch zusätzlich in einer Umgebung von stetig, dann ist die Funktion in auch total differenzierbar.
Differentialrechnung ist ein zentraler Unterrichtsgegenstand in der Sekundarstufe II und wird somit in allen Mathematik-Lehrbüchern dieser Stufe behandelt.
