Als globale Erwärmung bezeichnet man den Anstieg der Durchschnittstemperatur der erdnahen Atmosphäre und der Meere seit der Industrialisierung, in den letzten 50 bis 150 Jahren. Der berechnete Erwärmungstrend über die letzten 50 Jahre (1956 bis 2005) in Höhe von 0,13° C +-0,03°C pro Jahrzehnt ist fast zweimal so groß wie derjenige über die letzten 100 Jahre (1906 bis 2005) in Höhe von vs. 0,07° C +-0,02°C pro Jahrzehnt.[1] Dieser Prozess verläuft erheblich schneller als alle bekannten Erwärmungsphasen der letzten 65 Millionen Jahre.[2] Der Temperaturanstieg zwischen 1880 und 2012 beträgt nach Angaben des Weltklimarates (IPCC) 0,85 K.[3] Der IPCC schreibt in seinem 2013 erschienenen fünften Sachstandsbericht, dass es extrem wahrscheinlich ist, dass die beobachtete Erwärmung zu mehr als 50 % vom Menschen verursacht wird.[3]
Im Gegensatz zum Wetter, das kurzfristig-aktuelle Zustände der Atmosphäre beschreibt, werden hinsichtlich des Klimas Mittelwerte über längere Zeiträume erhoben. Üblicherweise werden dabei Normalperioden von jeweils 30 Jahren betrachtet. Oft werden die Bezeichnungen „Klimawandel“ und „globale Erwärmung“ synonym verwendet, obwohl die Gleichsetzung missverständlich ist: Der natürliche Klimawandel ist vom anthropogenen Einfluss überlagert. Die Klimaforschung sucht zu klären, welcher Anteil des beobachteten Temperaturanstiegs natürliche Ursachen hat und welcher Anteil vom Menschen verursacht wurde und weiterhin wird.
Die fortdauernde anthropogene Anreicherung der Erdatmosphäre mit Treibhausgasen (Kohlenstoffdioxid (CO2), Methan und Distickstoffmonoxid), die vor allem durch die Nutzung fossiler Energie (Brennstoffe), durch weltumfassende Entwaldung sowie Land- und insbesondere Viehwirtschaft freigesetzt werden, erhöht das Rückhaltevermögen für infrarote Wärmestrahlung in der Troposphäre. Nach Modellrechnungen trägt Kohlenstoffdioxid am meisten zur globalen Erwärmung bei.
Die ersten wissenschaftlichen Erkenntnisse zum menschengemachten (anthropogenen) Treibhauseffekt stammen aus der Mitte des 19. Jahrhunderts.[4] Etwa ab den 1960er Jahren gab es auf internationaler Ebene erste Gespräche zu dem Thema und spätestens seit den 1980er Jahren einen wissenschaftsbasierten Konsens und politische Maßnahmen. Dazu gehörte die Schaffung des Weltklimarats (IPCC), der den politischen Entscheidungsträgern und Regierungen zuarbeiten soll. Im IPCC wird der wissenschaftliche Erkenntnisstand zur globalen Erwärmung und zum anthropogenen Anteil daran diskutiert und in Berichten zusammengefasst.
Zu den laut Klimaforschung erwarteten und teils bereits beobachtbaren Folgen der globalen Erwärmung gehören je nach Erdregion: Meereis- und Gletscherschmelze, ein Meeresspiegelanstieg, das Auftauen von Permafrostböden, wachsende Dürrezonen und zunehmende Wetter-Extreme mit entsprechenden Rückwirkungen auf die Lebens- und Überlebenssituation von Menschen und Tieren (Artensterben). Nationale und internationale Klimapolitik zielt sowohl auf die Abschwächung des Klimawandels wie auch auf eine Anpassung an die zu erwartende Erwärmung.


In der Klimatologie ist es heute Konsens, dass die gestiegene Konzentration der vom Menschen in die Erdatmosphäre freigesetzten Treibhausgase mit hoher Wahrscheinlichkeit die wichtigste Ursache der globalen Erwärmung ist,[6][7] da ohne sie die gemessenen Temperaturen nicht zu erklären sind.[8][9][10]
Treibhausgase lassen die von der Sonne kommende kurzwellige Strahlung weitgehend ungehindert auf die Erde durch, absorbieren aber einen Großteil der von der Erde ausgestrahlten Infrarotstrahlung. Dadurch erwärmen sie sich und emittieren selbst Strahlung im längerwelligen Bereich (vgl. Kirchhoffsches Strahlungsgesetz). Der in Richtung der Erdoberfläche gerichtete Strahlungsanteil wird als atmosphärische Gegenstrahlung bezeichnet. Im isotropen Fall wird die absorbierte Energie je zur Hälfte in Richtung Erde und Weltall abgestrahlt. Hierdurch erwärmt sich die Erdoberfläche stärker, als wenn allein die kurzwellige Strahlung der Sonne sie erwärmen würde. Das IPCC schätzt den Grad des wissenschaftlichen Verständnisses über die Wirkung von Treibhausgasen als „hoch“ ein.[11]
Das Treibhausgas Wasserdampf (H2O) trägt mit 36 bis 66 %, Kohlenstoffdioxid (CO2) mit 9 bis 26 %, und Methan mit 4 bis 9 % zum natürlichen Treibhauseffekt bei.[12] Die große Bandbreite erklärt sich folgendermaßen: Einerseits gibt es sowohl örtlich wie auch zeitlich große Schwankungen in der Konzentration dieser Gase. Zum Anderen überlappen sich deren Absorptionsspektren. Beispiel: Strahlung, die von Wasserdampf bereits absorbiert wurde, kann von Kohlenstoffdioxid nicht mehr absorbiert werden. Das bedeutet, dass in einer (Eis-)Wüste, in der Wasserdampf nur wenig zum Treibhauseffekt beiträgt, die übrigen Treibhausgase mehr zum Gesamttreibhauseffekt beitragen als in den feuchten Tropen.
Da die genannten Treibhausgase natürliche Bestandteile der Atmosphäre sind, wird die von ihnen verursachte Temperaturerhöhung als natürlicher Treibhauseffekt bezeichnet. Der natürliche Treibhauseffekt führt dazu, dass die Durchschnittstemperatur der Erde bei +15 °C liegt. Ohne den natürlichen Treibhauseffekt läge sie bei ca. −18 °C.[13]
Seit der Industriellen Revolution verstärkt der Mensch den natürlichen Treibhauseffekt durch den Ausstoß von Treibhausgasen, wie messtechnisch belegt werden konnte.[14][15]
Der Anteil aller vier Bestandteile des natürlichen Treibhauseffekts in der Atmosphäre ist seit dem Beginn der industriellen Revolution gestiegen. Die Geschwindigkeit des Konzentrationsanstiegs ist die schnellste der letzten 22.000 Jahre.[3]
Die Konzentration von Kohlenstoffdioxid in der Erdatmosphäre ist vor allem durch die Nutzung fossiler Energie, durch die Zementindustrie und großflächige Entwaldung seit Beginn der Industrialisierung von ca. 280 ppmV um 40 % auf ca. 400 ppmV (parts per million, Teile pro Million Volumenanteil) im Jahr 2015 gestiegen.[16] Dies ist wahrscheinlich der höchste Wert seit wenigstens 15 bis 20 Millionen Jahren.[17][18] Nach Messungen aus Eisbohrkernen betrug die CO2-Konzentration in den letzten 800.000 Jahren nie mehr als 300 ppmV.[19][20]
Der Volumenanteil von Methan stieg von 730 ppbV im Jahr 1750 auf 1.800 ppbV (parts per billion, Teile pro Milliarde Volumenanteil) im Jahr 2011 an. Dies ist ein Anstieg um 150 % und wie bei Kohlenstoffdioxid der höchste Stand seit mindestens 800.000 Jahren.[21] Als eine der Ursachen hierfür ist die Viehhaltung[22] anzuführen, gefolgt von weiteren landwirtschaftlichen Aktivitäten wie dem Anbau von Reis. Das Treibhauspotenzial von 1 kg Methan ist, auf einen Zeitraum von 100 Jahren betrachtet, 25 mal höher als das von 1 kg Kohlenstoffdioxid.[23] Nach einer neueren Untersuchung beträgt dieser Faktor sogar 33, wenn Wechselwirkungen mit atmosphärischen Aerosolen berücksichtigt werden.[24] In einer sauerstoffhaltigen Atmosphäre wird Methan jedoch oxidiert, meist durch Hydroxyl-Radikale. Ein einmal in die Atmosphäre gelangtes Methan-Molekül hat dort eine durchschnittliche Verweilzeit von zwölf Jahren.[23]
Im Unterschied dazu liegt die Verweildauer von Kohlenstoffdioxid teilweise im Bereich von Jahrhunderten. Die Ozeane nehmen atmosphärisches Kohlenstoffdioxid zwar sehr rasch auf: Ein CO2-Molekül wird nach durchschnittlich fünf Jahren in den Ozeanen gelöst. Diese geben es aber auch wieder an die Atmosphäre ab, so dass ein Teil des vom Menschen emittierten Kohlenstoffdioxids letztlich für mehrere Jahrhunderte (ca. 30 %) und ein weiterer Teil (ca. 20 %) sogar für Jahrtausende im Kohlenstoffkreislauf von Hydrosphäre und Atmosphäre verbleibt.[25]
Der Volumenanteil von Lachgas stieg von vorindustriell 270 ppbV auf mittlerweile 323 ppbV.[26] Durch sein Absorptionsspektrum trägt es dazu bei, ein sonst zum Weltall hin offenes Strahlungsfenster zu schließen. Trotz seiner sehr geringen Konzentration in der Atmosphäre trägt es zum anthropogenen Treibhauseffekt etwa 6 % bei, da seine Wirkung als Treibhausgas 298 mal stärker ist als die von Kohlenstoffdioxid; daneben hat es auch eine recht hohe atmosphärische Verweilzeit von 114 Jahren.[23]
Die Wasserdampfkonzentration der Atmosphäre wird durch anthropogene Wasserdampfemissionen nicht signifikant verändert, da zusätzlich in die Atmosphäre eingebrachtes Wasser innerhalb weniger Tage auskondensiert. Steigende globale Durchschnittstemperaturen führen jedoch zu einem höheren Dampfdruck, das heißt einer stärkeren Verdunstung. Der damit global ansteigende Wasserdampfgehalt der Atmosphäre treibt die globale Erwärmung zusätzlich an. Wasserdampf wirkt somit im Wesentlichen als Rückkopplungsglied. Diese Wasserdampf-Rückkopplung ist neben der Eis-Albedo-Rückkopplung die stärkste, positiv wirkende Rückkopplung im globalen Klimageschehen.[27]
Neben Treibhausgasen beeinflussen auch die Sonnenaktivität sowie Aerosole das Erdklima. Aerosole liefern von allen festgestellten Beiträgen zum Strahlungsantrieb die größte Unsicherheit, und das Verständnis über sie wird vom IPCC als „gering“ bezeichnet.[11] Die Wirkung eines Aerosols auf die Lufttemperatur ist abhängig von seiner Flughöhe in der Atmosphäre. In der untersten Atmosphärenschicht, der Troposphäre, sorgen Rußpartikel für einen Temperaturanstieg, da sie das Sonnenlicht absorbieren und anschließend Wärmestrahlung abgeben. Die verringerte Reflektivität (Albedo) von Schnee- und Eisflächen und anschließend darauf niedergegangenen Rußpartikeln wirkt ebenfalls erwärmend. In höheren Luftschichten hingegen sorgen Mineralpartikel durch ihre abschirmende Wirkung dafür, dass es an der Erdoberfläche kühler wird.[28]
Einen großen Unsicherheitsfaktor bei der Bemessung der Klimawirkung von Aerosolen stellt ihr Einfluss auf die ebenfalls nicht vollständig verstandene Wolkenbildung dar. Trotz der Unsicherheiten wird Aerosolen insgesamt eine deutlich abkühlende Wirkung zugemessen.
Der zwischen den 1940er bis Mitte der 1970er Jahre beobachtete Rückgang der globalen Durchschnittstemperaturen sowie die Stagnation der globalen Durchschnittstemperaturen seit ca. dem Jahr 2000 wird zum großen Teil der kühlenden Wirkung von Sulfataerosolen zugeschrieben,[29] die im ersten Fall in Europa und den USA und im letzten Fall in der Volksrepublik China und Indien zu verorten waren.[30]
Eine Reihe von Faktoren beeinflussen das globale Klimasystem. In der Diskussion um die Ursachen der globalen Erwärmung werden oft Faktoren genannt, die nachrangig sind oder sogar kühlend auf das Klimasystem wirken.
So ist eine veränderte kosmische Strahlung nicht für die gegenwärtig beobachtete Erwärmung verantwortlich.[31][32][33]
Die Erde befindet sich seit ca. 1850, also etwa dem Beginn der industriellen Revolution, in einer Phase der Wiedererwärmung aus der kleinen Eiszeit. Ohne die Eingriffe des Menschen in den natürlichen Klimaverlauf würde sich aber der seit 6000 Jahren bestehende Abkühlungstrend fortsetzen, der – je nach Literaturquelle – in 20.000 bis 50.000 Jahren zur nächsten Eiszeit geführt hätte.[34][35]
Die Annahme, das Ozonloch sei eine wesentliche Ursache der globalen Erwärmung, ist ebenso falsch, denn der Ozonabbau wärmt nicht das Klima der Erde, sondern kühlt es.[36] Der Ozonabbau wirkt hierbei auf zweierlei Arten: Die verringerte Ozonkonzentration kühlt die Stratosphäre, da die UV-Strahlung dort nicht mehr absorbiert wird, wärmt hingegen die Troposphäre, wo sie absorbiert wird. Die kältere Stratosphäre schickt weniger wärmende Infrarotstrahlung nach unten und kühlt damit die Troposphäre. Insgesamt dominiert der Kühlungseffekt, so dass das IPCC folgert, dass der beobachtete Ozonschwund im Verlauf der letzten beiden Dekaden zu einem negativen Strahlungsantrieb auf das Klimasystem geführt hat,[37] der sich auf etwa −0,15 ± 0,10 Watt pro Quadratmeter (W/m²) beziffern lässt.[38]
Veränderungen in der Sonne wird ein geringer Einfluss auf die gemessene globale Erwärmung zugesprochen.[39] Die seit 1978 direkt vom Orbit aus gemessene Änderung der Sonnenaktivität ist bei weitem zu klein, um als Hauptursache für die seither beobachtete Temperaturentwicklung in Frage zu kommen.[40][41][42][43] Seit den 1960er Jahren ist der Verlauf der globalen Durchschnittstemperatur von der Sonnenaktivität entkoppelt.[44]
Das IPCC schätzt den zusätzlichen Strahlungsantrieb durch die Sonne seit Beginn der Industrialisierung auf etwa 0,12 Watt pro Quadratmeter. Das 90-Prozent-Konfidenzintervall für diese Schätzung wird mit 0,06 bis 0,30 W/m² angegeben; im Vergleich dazu tragen die anthropogenen Treibhausgase mit 2,63 (± 0,26) W/m² zur Erwärmung bei. Das IPCC schreibt, dass der Grad des wissenschaftlichen Verständnisses bezüglich des Einflusses solarer Variabilität (siehe auch Streuung) vom Dritten zum Vierten Sachstandsbericht von „sehr gering“ auf „gering“ zugenommen hat.[11]
Bei fast allen Prozessen entsteht Wärme, so bei der Produktion von elektrischem Strom, bei der Nutzung von Verbrennungsmotoren (siehe Wirkungsgrad) oder beim Betrieb von Computern. In den USA und Westeuropa trugen Gebäudeheizung, industrielle Prozesse und Verbrennungsmotoren im Jahr 2008 mit 0,39 W/m² bzw. 0,68 W/m² zur Erwärmung bei und haben damit einen gewissen Einfluss auf das regionale Klimageschehen. Weltweit gesehen betrug dieser Wert 0,028 W/m² (also nur etwa 1 % der globalen Erwärmung).[45][46]
Als Hauptanzeichen für die derzeitige globale Erwärmung gelten die seit etwa 1860 vorliegenden weltweiten Temperaturmessungen sowie die Auswertungen verschiedener Klimaarchive. Verglichen mit den Schwankungen der Jahreszeiten sowie beim Wechsel von Tag und Nacht erscheinen die im Folgenden genannten Zahlen klein; als globale Änderung des Klimas bedeuten sie jedoch sehr viel, wenn man die um nur etwa 6 K niedriger liegende Durchschnittstemperatur auf der Erde während der letzten Eiszeit bedenkt.[47]
Im Jahr 2005 wurde u.a. aufgrund der gemessenen Temperaturzunahme der Meere über eine Dekade errechnet, dass die Erde 0,85 Watt pro Quadratmeter mehr Leistung aufnimmt als sie ins All abstrahlt.[48][49]
Zwischen 1880 und 2012 nahmen die global gemittelten, bodennahen Lufttemperaturen um 0,85 °C zu.[3] Eine deutliche Erwärmungsphase war zwischen 1910 und 1945 zu beobachten, in der aufgrund der noch vergleichsweise geringen Konzentration von Treibhausgasen auch natürliche Schwankungen einen deutlichen Einfluss hatten. Am ausgeprägtesten ist die Erwärmung von 1975 bis heute. Nach NOAA und NASA waren 2010 und 2005 die global wärmsten Jahre seit Beginn der Aufzeichnungen, dicht gefolgt von 1998.[50][51]
Insbesondere bei kurzen Zeitreihen ist zu berücksichtigen, dass Anfangs- und Endjahr starken Einfluss auf den Trend haben können und somit nicht zwingend langfristige Trends widerspiegeln müssen. Ein Beispiel für eine solche Abweichung ist der Zeitraum zwischen 1998 und 2012, der mit einem starken El Niño und damit außergewöhnlich heißen Jahr begann, weshalb der Erwärmungstrend mit 0,05° C pro Jahrzehnt in diesem Zeitraum deutlich unter dem langfristigen Trend von 0,12 °C pro Jahrzehnt im Zeitraum 1951–2012 zurückblieb.[52]
Die 30 Jahre von 1983 bis 2012 waren auf der Nordhalbkugel die wärmste Normalperiode seit 1400 Jahren.[3] 2014 gilt als das wärmste Jahr seit Beginn der Wetteraufzeichnungen im Jahr 1880.[53]
Im Zeitabschnitt 1979–2012 (34 Jahre) nahm die globale Durchschnittstemperatur nach Bodenmessungen von 0,151 bis 0,161 °C pro Jahrzehnt zu.[54]
Die linearen Trends der mittleren globalen Erdoberflächentemperatur (GMST) in den Zeitabschnitten 1880–2012 und 1979–2012 betragen:[55]
Die linearen Trends der mittleren globalen Erdoberflächentemperatur für die 15-Jahres-Perioden betragen:[52]
Die linearen Trends der mittleren globalen Erdoberflächentemperatur nach NCDC/NESDIS/NOAA in den Zeitabschnitten 1880 - 2014 und 1998 - 2014 betragen: [62]
Die Daten der Satellitenmessungen werden von verschiedenen Forschungsgruppen ausgewertet, die zu leicht unterschiedlichen Ergebnissen kommen. Nach der Gruppe RSS beträgt der Trend 0,12 K und nach Messungen an der University of Alabama in Huntsville 0,14 K pro Jahrzehnt in dem Zeitabschnitt 1979 -2014.[63][64] Hierbei ist zu beachten, dass Satellitenmessungen (UAH, RSS) und Messungen an der Erdoberfläche nicht direkt vergleichbar sind, da sie unterschiedliche physikalische Eigenschaften wiedergeben.[65][66]
Die Trendwerte (°C/Dekade) der globalen mittleren Erdoberflächen- und Oberluftanomalien sind aus den unterschiedlichen Datenquellen und Perioden im Dritten Sachstandbericht des Intergovernmental Panel on Climate Change (IPCC, Abschnitt 2.2.4, Tabelle 2.3) angezeigt und verglichen. [67]
Die dekadischen linearen Trends der mittleren globalen Oberlufttemperaturen der unteren Troposphäre (TLT) im Zeitabschnitt 1979 - 2015 betragen: [68] [69] [70]
In einer 2007 erschienenen Studie konnte der natürliche Anteil der Erwärmung des 20. Jahrhunderts auf unter 0,2 K eingegrenzt werden.[71]
Neben der Luft haben sich auch die Ozeane erwärmt, die über 90 % der Wärmeenergie aufgenommen haben.[72] Während sich die Weltmeere seit 1955 aufgrund ihres enormen Volumens und ihrer großen Temperaturträgheit insgesamt nur um 0,04 K aufgeheizt haben, erhöhte sich ihre Oberflächentemperatur im selben Zeitraum um 0,6 K.[73] Im Bereich zwischen der Meeresoberfläche bis zu einer Tiefe von 75 Metern stieg die Temperatur von 1971 bis 2010 um durchschnittlich 0,11 K pro Jahrzehnt an.[3]
Der Energieinhalt der Weltmeere nahm zwischen Mitte der 1950er Jahre bis 1998 um ca. 14,5 × 1022 Joule zu, was einer Heizleistung von 0,2 Watt pro m² der gesamten Erdoberfläche entspricht.[74] Die Energiezunahme der Weltmeere in Höhe von 14,5 × 1022 Joule entspricht der Energie von 100 Millionen Hiroshima-Atombomben; diese Energiemenge würde die unteren 10 Kilometer der Atmosphäre um 22 K erwärmen.[75]
Seit dem Jahr 2000 wird der Wärmeinhalt der Ozeane mit Hilfe des Argo-Programms vermessen, wodurch seit dieser Zeit erheblich genauere Daten über den Zustand wie auch die Veränderung von klimatologisch relevanten Messwerten (z. B. Wärmeinhalt, Salinität, Tiefenprofil) verfügbar sind.
Luft über Landflächen erwärmt sich allgemein stärker als über Wasserflächen,[76] was in der zweiten Abbildung dieses Artikels erkennbar ist. Die Erwärmung der Landflächen zwischen 1970 und 2014 lag im Mittel bei 0,26 K und damit mehr als doppelt hoch wie über dem Meer, das sich im selben Zeitraum um 0,12 K erwärmte.[77] Dementsprechend stiegen die Temperaturen auf der Nordhalbkugel, auf der sich der Großteil der Landflächen befindet, in den vergangenen 100 Jahren stärker an als auf der Südhalbkugel, wie auch die nebenstehende Grafik zeigt.[78]
Die Nacht- und Wintertemperaturen stiegen etwas stärker an als die Tages- und Sommertemperaturen.[79][80] Aufgeteilt nach Jahreszeiten wurde die größte Erwärmung während der Wintermonate gemessen, und dabei besonders stark über dem westlichen Nordamerika, Skandinavien und Sibirien.[81] Im Frühling stiegen die Temperaturen am stärksten in Europa sowie in Nord- und Ostasien an. Im Sommer waren Europa und Nordafrika am stärksten betroffen, und im Herbst entfiel die größte Steigerung auf den Norden Nordamerikas, Grönland und Ostasien.[82] Besonders markant fiel die Erwärmung in der Arktis aus, wo sie im jährlichen Mittel etwa doppelt so hoch ist wie im globalen Durchschnitt.[83][84] Mit Ausnahme weniger Regionen ist die Erwärmung seit 1979 weltweit nachweisbar.[82]
Für die verschiedenen Luftschichten der Erdatmosphäre wird theoretisch eine unterschiedliche Erwärmung erwartet und faktisch auch gemessen. Während sich die Erdoberfläche und die niedrige bis mittlere Troposphäre erwärmen sollten, lassen Modelle für die höher gelegene Stratosphäre eine Abkühlung vermuten.[85] Tatsächlich wurde genau dieses Muster in Messungen gefunden. Die Satellitendaten zeigen eine Abnahme der Temperatur der unteren Stratosphäre von 0,314 K pro Jahrzehnt während der letzten 30 Jahre.[86] Diese Abkühlung wird zum einen durch den verstärkten Treibhauseffekt und zum anderen durch Ozonschwund durch FCKWs in der Stratosphäre verursacht,[87][88] siehe auch Montrealer Protokolls zum Schutz der Ozonschicht. Wäre die Sonne maßgebliche Ursache, hätten sich sowohl die oberflächennahen Schichten, die niedere bis mittlere Troposphäre wie auch die Stratosphäre erwärmen müssen.[85] Nach dem gegenwärtigen Verständnis heißt dies, dass der überwiegende Teil der beobachteten Erwärmung durch menschliche Aktivitäten verursacht sein muss.
Auch bei Annahme einer Erwärmung um 4 K bis zum Ende des 21. Jahrhunderts wird es im Verlauf immer wieder Phasen der Stagnation oder sogar der Abkühlung geben. Diese Phasen können bis zu ca. 15 Jahre andauern.[89] Ursachen sind der elfjährige Sonnenfleckenzyklus, kühlende starke Vulkanausbrüche, sowie die natürliche Eigenschaft des Weltklimas, einen schwingenden Temperaturverlauf zu zeigen (AMO, PDO, ENSO). So kann beispielsweise das Auftreten von El-Niño- bzw. La-Niña-Ereignissen die globale Durchschnittstemperatur von einem Jahr auf das andere um 0,2 K erhöhen bzw. absenken und für wenige Jahre den jährlichen Erwärmungstrend von ca. 0,02 K überdecken aber auch verstärken.[90][91]
Das globale Klimasystem ist von Rückkopplungen geprägt, die Temperaturveränderungen verstärken oder abschwächen. Eine die Ursache verstärkende Rückkopplung wird als positive Rückkopplung bezeichnet. Bei bestimmten Zuständen des globalen Klimageschehen sind nach heutigem Kenntnisstand die positiven Rückkopplungen deutlich stärker als die negativen Rückkopplungen, so dass das Klimasystem in einen anderen Zustand kippen kann.
Die beiden stärksten, positiv wirkenden Rückkopplungsprozesse sind die Eis-Albedo-Rückkopplung und die Wasserdampf-Rückkopplung. Ein Abschmelzen der Polkappen bewirkt durch verminderte Reflexion einen zusätzlichen Energieeintrag über die Eis-Albedo-Rückkopplung. Die Wasserdampfrückkopplung entsteht dadurch, dass die Atmosphäre einer wärmeren Welt auch mehr Wasserdampf enthält. Da Wasserdampf das mit Abstand mächtigste Treibhausgas ist, wird dadurch ein eingeleiteter Erwärmungsprozess weiter verstärkt – unabhängig davon, was diese Erwärmung letztlich ausgelöst hat.[27] Gleiches gilt auch bei einer Abkühlung, die durch dieselben Prozesse weiter verstärkt wird. Zur quantitativen Beschreibung der Reaktion des Klimas auf Veränderungen der Strahlungsbilanz wurde der Begriff der Klimasensitivität etabliert. Mit ihr lassen sich unterschiedliche Einflussgrößen gut miteinander vergleichen.
Neben diesen beiden, physikalisch gut verstandenen Rückkopplungen, existieren jedoch noch weitere Rückkopplungsfaktoren, deren Wirken weit schwieriger abschätzbar ist:
Wolken beeinflussen das Klima der Erde maßgeblich, indem sie einen Teil der einfallenden Strahlung reflektieren. Strahlung, die von der Sonne kommt, wird zurück ins All, Strahlung darunter liegender Atmosphärenschichten in Richtung Boden reflektiert. Die Helligkeit der Wolken stammt von kurzwelliger Strahlung im sichtbaren Wellenlängenbereich.[92]
Eine größere optische Dicke niedriger Wolken bewirkt, dass mehr Energie ins All zurückgestrahlt wird; die Temperatur der Erde sinkt. Umgekehrt lassen weniger dichte Wolken mehr Sonnenstrahlung passieren, was darunter liegende Atmosphärenschichten wärmt. Niedrige Wolken sind oft dicht und reflektieren viel Sonnenlicht zurück in den Weltraum. Sie liegen auch niedriger in der Atmosphäre, wo Temperaturen höher sind und strahlen deshalb mehr Wärme ab. Die Tendenz niedriger Wolken ist daher, die Erde zu kühlen.[92]
Hohe Wolken sind meist dünn und nicht sehr reflektierend. Sie lassen einen Großteil der Sonnenwärme durch und da sie sehr hoch liegen, wo die Lufttemperatur sehr niedrig ist, strahlen diese Wolken nicht viel Wärme ab. Die Tendenz hoher Wolken ist, die Erde zu erwärmen.[92]
Die Vegetation und die Beschaffenheit des Bodens und insbesondere seine Versiegelung, Entwaldung oder landwirtschaftliche Nutzung haben maßgeblichen Einfluss auf die Verdunstung und somit auf die Wolkenbildung und das Klima.[92] Nachgewiesen wurde ebenfalls eine Verminderung der Wolkenbildung durch Pflanzen, welche bei einem Kohlenstoffdioxid-Anstieg bis zu 15 Prozent weniger Wasserdampf freigeben und somit die Wolkenbildung reduzieren.[93][94]
Vegetation und Bodenbeschaffenheit reflektieren je nach Beschaffenheit das einfallende Sonnenlicht unterschiedlich. Reflektiertes Sonnenlicht wird als kurzwellige Sonnenstrahlung in den Weltraum zurückgeworfen (ansonsten wäre die Erdoberfläche aus Sicht des Weltalls ohne Infrarotkamera schwarz). Albedo ist ein Maß für das Rückstrahlvermögen von diffus reflektierenden (reemittierenden), also nicht spiegelnden und nicht selbst leuchtenden Oberflächen.
Nicht nur der Verbrauch von fossilen Energieträgern führt zu einer Freisetzung von Treibhausgasen. Die intensive Bestellung von Ackerland und die Entwaldung sind ebenfalls eine bedeutende Treibhausgasquelle. Die Vegetation benötigt für den Prozess der Photosynthese Kohlenstoffdioxid zum Wachsen. Bäume benötigen CO2 in größeren Mengen als Getreide. Der Boden ist eine wichtige Senke, da er organisches, kohlenstoffhaltiges Material enthält. Durch ackerbauliche Tätigkeiten wird dieser gespeicherte Kohlenstoff in Form von Kohlenstoffdioxid jedoch teilweise freigesetzt.[95]
Im Permafrost Westsibiriens lagern 70 Milliarden Tonnen Methan, in der Tiefsee ungleich größere Mengen Gashydratvorkommen.[96][97] Durch lokale Klimaveränderungen (aktuell: +3 K innerhalb von 40 Jahren in Westsibirien) könnten auch bei geringer globaler Erwärmung regional kritische Temperaturen erreicht werden; es besteht die Gefahr der Freisetzung der dort gespeicherten Methanressourcen in die Atmosphäre.[98]
Eine Berechnung unter Annahme derartiger Rückkopplungen wurde von Wissenschaftlern der University of California, Berkeley erstellt, die annahmen, dass der Kohlenstoffdioxidgehalt der Atmosphäre sich von den derzeitigen etwa 390 ppmV bis 2100 auf etwa 550 ppmV erhöhen wird. Dies sei allein der von der Menschheit bewirkte anthropogene Zuwachs. Die erhöhte Temperatur führt zu zusätzlicher Freisetzung von Treibhausgasen, insbesondere Kohlenstoffdioxid und Methan. Bei ansteigender Temperatur erfolgt eine erhöhte Freisetzung von Kohlenstoffdioxid aus den Weltmeeren und die beschleunigte Verrottung von Biomasse, was zusätzliches Methan und Kohlenstoffdioxid freisetzt. Durch diese positive Rückkopplung könnte die globale Erwärmung um 2 K stärker ausfallen als gegenwärtig angenommen wird.[99] Aus diesem und anderen Gründen schätzt Barrie Pittock in Eos, der Publikation der American Geophysical Union, dass die zukünftige Erwärmung über die vom IPCC genannten Bandbreiten hinausgehen könnte. Er nennt acht Gründe für seine Vermutung, darunter unter anderem auch den Rückgang der globalen Verdunkelung und Rückkopplungseffekte durch Biomasse.[100]
Bei einer Verdoppelung der CO2-Konzentration in der Atmosphäre gehen Klimaforscher davon aus, dass die Erhöhung der Erdmitteltemperatur innerhalb von 1,5 bis 4,5 K liegen wird.[3] Dieser Wert ist auch als Klimasensitivität bekannt und ist auf das vorindustrielle Niveau (von 1750) bezogen, ebenso wie der dafür maßgebende Strahlungsantrieb; mit dieser Größe werden alle bekannten, die Strahlungsbilanz der Erde beeinflussenden Faktoren vom IPCC quantitativ beschrieben und vergleichbar gemacht. Das IPCC rechnet, abhängig von den Zuwachsraten aller Treibhausgase und dem angewandten Modell, bis 2100 mit einer Zunahme der globalen Durchschnittstemperatur um 0,9 bis 5,4 K.[3]Zum Vergleich: die schnellste Erwärmung im Verlauf von der letzten Eiszeit zur heutigen Warmzeit war eine Erwärmung um etwa ein Grad pro 1000 Jahre.[101][102]
Nach einer Studie[103] an der Carnegie Institution for Science, in der die Ergebnisse eines Kohlenstoff-Zyklus-Modells mit Daten aus Vergleichsuntersuchungen zwischen Klimamodellen des fünften IPCC-Sachstandsberichts ausgewertet wurden, reagiert das globale Klimasystem auf einen CO2-Eintrag mit einer zeitlichen Verzögerung von etwa 10 Jahren mit einer Sprungfunktion; das bedeutet, dass die Erwärmung nach etwa 10 Jahren ihr Maximum erreicht und dann für sehr lange Zeiträume dort verharrt.[104]
Nach Modellergebnissen des Met Office von Ende 2012 wird davon ausgegangen, dass für den Zeitraum 2013–2017 (in Bezug auf den Referenzzeitraum von 1971 bis 2000) eine globale Erwärmung von 0,43 K (min. 0,28 K, max. 0,59 K) erwartet werden kann. Das Metoffice ergänzt, dass dekadische Vorhersagen experimentellen Charakter haben.[105]
Der dabei maßgebliche, allerdings auch der mit der größten Unsicherheit behaftete Parameter ist die Prognose über die künftige Entwicklung der Weltwirtschaft. Da das Wirtschaftswachstum der Welt in der Vergangenheit stark mit dem Verbrauch an fossilen Energieträgern korrelierte[106] und dies auch in der näheren Zukunft erwartet werden kann, erklärt sich hieraus die relativ große Bandbreite der von den Klimatologen projizierten globalen Erwärmung.
Ein weiterer wahrscheinlicher Einfluss ist ein Rückgang der Förderung konventionellen Erdöls aufgrund des Eintretens des globalen Erdölfördermaximums (des sogenannten „Peak Oil“), das von vielen Experten bis etwa 2030, möglicherweise jedoch auch deutlich früher, erwartet wird. Wird das dann fehlende Öl durch nicht-konventionelles Erdöl wie z. B. Ölsande ausgeglichen, so kann sich die Menge an Treibhausgasen bis zu einem Faktor von 2,5 vergrößern und Anstrengungen zur Reduktion von Emissionen zunichtemachen.[107][108][109]
Nach einer im Jahr 2009 erschienenen Studie wird die gegenwärtig bereits angestoßene Erwärmung noch für mindestens 1000 Jahre irreversibel sein, selbst wenn heute alle Treibhausgasemissionen vollständig gestoppt würden.[110] In weiteren Szenarien wurden die Emissionen schrittweise bis zum Ende unseres Jahrhunderts fortgesetzt und dann ebenfalls abrupt beendet. Dabei wurden wesentliche Annahmen und Aussagen, die im 4. IPCC-Bericht über die folgenden 1000 Jahre gemacht wurden,[11][111] bestätigt und verfeinert. Langfristige Klimasimulationen deuten darauf hin, dass sich die von einer erhöhten Kohlenstoffdioxidkonzentration aufgeheizte Erde nur um ca. ein Grad pro 12.000 Jahre abkühlen wird.[112]
Implizit wird dabei ein nahezu verschwindendes Wachstum der anthropogenen Abwärmeproduktion vorausgesetzt, die anderenfalls in den nächsten Jahrhunderten zu noch höheren Temperaturen führen würde, wie einfache Abschätzungen zeigen.[113] Simulationsrechnungen zum Einfluss anthropogener Abwärme ergaben Beiträge zur kontinentalen Temperaturerhöhung von einigen Zehntel Grad für das Jahr 2100, wenn eine jährliche Wachstumsrate der Energieproduktion aus nicht erneuerbaren Quellen von 2 % angenommen wird.[45][114] Dies entspricht der Fortschreibung des Wachstums seit der ersten Ölkrise von 1973 und schließt die Möglichkeit einer Nutzung der Kernfusion mit ein. Bei Fortsetzung ergäbe sich ein globaler Beitrag von 3 Grad in 280 Jahren[115], der zur anhaltenden Wirkung der Treibhausgase hinzukäme. (Ähnliches wurde bereits 1973 abgeschätzt.[113]) Ein realistischeres Wachstumsszenario (mit anfänglicher Unterscheidung zwischen OECD- und Nicht-OECD-Ländern und einer Stabilisierung der Weltbevölkerung bei 9 Milliarden ab dem Jahr 2100) liefert den Beitrag von 3 Grad in 320 Jahren. Anhaltendes Wirtschaftswachstum, „unser bisheriges Mantra“ (laut Klaus Töpfer[116]), führt somit auch nach diesen Szenarien zu abwegigen Konsequenzen. Wie besonders im Abschnitt 5.2 („Das IPCC“) in Zusammenhang mit der Box zu den Projektionen bis 2100 noch deutlicher wird, ist bereits vorher ein Kurswechsel notwendig.[117] Er entspräche einem Wechsel von den wachstumsorientierten A- zu den nachhaltigen B-Szenarien des IPCC.[118]
Aufbauend auf die Entdeckung des Treibhauseffektes durch Jean Baptiste Joseph Fourier im Jahr 1824, identifizierte John Tyndall 1862 einige der für diesen Effekt verantwortlichen Gase, allen voran Wasserdampf und Kohlenstoffdioxid.[11] Hieran anknüpfend, veröffentlichte Svante Arrhenius[119] 1896 als Erster die Hypothese, dass die anthropogene CO2-Anreicherung in der Atmosphäre die Erdtemperatur erhöhen könne,[120] womit die „Wissenschaft von der globalen Erwärmung“ im engeren Sinne begann.
Im Jahr 1908 publizierte der britische Meteorologe und spätere Präsident der Royal Meteorological Society Ernest Gold ein Paper zur Stratosphäre.[121] Er schrieb darin, dass die Temperatur der Tropopause mit steigender CO2-Konzentration steigt. Es ist dies ein Kennzeichen der globalen Erwärmung, das fast ein Jahrhundert später auch gemessen werden konnte.[122]
In den späten 1950er Jahren wurde erstmals nachgewiesen, dass der Kohlenstoffdioxidgehalt der Atmosphäre ansteigt. Auf Initiative von Roger Revelle startete Charles David Keeling 1958 auf dem Berg Mauna Loa (Hawaii, Big Island) regelmäßige Messungen des CO2-Gehalts der Atmosphäre (Keeling-Kurve). Gilbert Plass nutzte 1956 erstmals Computer und erheblich genauere Absorptionsspektren des CO2 zur Berechnung der zu erwartenden Erwärmung. Er erhielt 3,6 K (3,6 °C) als Wert für die Klimasensitivität.[123]
Die ersten Computerprogramme zur Modellierung des Weltklimas wurden Ende der 1960er Jahre geschrieben.
1979 schrieb die National Academy of Sciences der USA im sog. Charney-Report, dass ein Anstieg der Kohlenstoffdioxidkonzentration ohne Zweifel mit einer signifikanten Klimaerwärmung verknüpft sei. Deutliche Effekte seien aufgrund der Trägheit des Klimasystems jedoch erst in einigen Jahrzehnten zu erwarten.[124]
Die Erforschung von Ursachen und Folgen der globalen Erwärmung ist seit ihrem Beginn eng mit der Analyse der klimatischen Bedingungen vergangener Zeiten verknüpft. Svante Arrhenius, der als erster darauf hinwies, dass der Mensch durch die Emission von CO2 die Erde erwärmt, erkannte bei der Suche nach den Ursachen der Eiszeiten den klimatischen Einfluss wechselnder Konzentrationen von Kohlenstoffdioxid in der Erdatmosphäre.[125]
So wie Erdbeben und Vulkanausbrüche sind auch Klimawandel etwas Natürliches. Seit der Entstehung der Erde hat sich das irdische Klima ständig verändert und es wird sich auch künftig ändern. In erster Linie verantwortlich dafür waren eine wechselnde Konzentration und Zusammensetzung der Treibhausgase in der Atmosphäre durch die unterschiedliche Intensität von Vulkanismus und Erosion. Weitere klimawirksame Faktoren sind die variable Sonneneinstrahlung, unter anderem auf Grund der Milanković-Zyklen, sowie eine durch die Plattentektonik verursachte permanente Umgestaltung und Verschiebung der Kontinente[126] mit einer daraus resultierenden Verlagerung großer Meeresströmungen. Landmassen an den Polen förderten die Bildung von Eiskappen, und veränderte ozeanische Strömungen lenkten Wärme entweder von den Polen weg oder zu diesen hin und beeinflussten auf diese Weise die Stärke der sehr mächtigen Eis-Albedo-Rückkopplung.[127]
Obwohl Leuchtkraft und Strahlungsleistung der Sonne am Beginn der Erdgeschichte etwa 30 Prozent unter den heutigen Werten lagen, herrschten in der gesamten Zeit Bedingungen, unter denen flüssiges Wasser existieren konnte. Dieses Paradoxon der schwachen, jungen Sonne genannte Phänomen führte in den 1980er Jahren zur Hypothese eines „CO2-Thermostats“. Er hielt die Temperaturen der Erde über Jahrmilliarden konstant in Bereichen, die Leben auf unserem Planeten ermöglichten.
Wenn Vulkane vermehrt CO2 ausstießen, so dass die Temperaturen anstiegen, erhöhte sich der Grad der Verwitterung, wodurch mehr CO2 gebunden wurde. War die Erde kalt und die Konzentration des Treibhausgases gering, wurde die Verwitterung durch die Vereisung weiter Landflächen stark verringert.[128] Das durch den Vulkanismus weiter in die Atmosphäre strömende Treibhausgas reicherte sich dort bis zu einem gewissen Kipppunkt an, um schließlich ein globales Tauwetter auszulösen. Der Nachteil dieses Mechanismus besteht darin, dass er mehrere Jahrtausende für die Korrektur von Treibhausgaskonzentrationen und Temperaturen benötigt, und es sind mehrere Fälle bekannt, bei denen er versagte.
Im Verlauf – vermutlich mehrerer – Schneeball-Erde-Ereignisse während des Neoproterozoikums vor rund 750 bis 600 Millionen Jahren fror die Erdoberfläche fast vollkommen zu, und zur Zeit des wahrscheinlich größten Massenaussterbens vor 250 Millionen Jahren war der Planet ein Supertreibhaus mit drastisch höheren Temperaturen als heute.[129]
Man nimmt an, dass die große Sauerstoffkatastrophe vor 2,3 Milliarden Jahren einen Zusammenbruch der Methankonzentration in der Atmosphäre bewirkte. Dies verminderte den Treibhauseffekt so stark, dass daraus eine großflächige und lang andauernde Vereisung der Erde während der huronischen Eiszeit resultierte. Das letzte derartige Ereignis fand unmittelbar vor der kambrischen Explosion vor 635 Millionen Jahren statt und wird Marinoische Eiszeit genannt. Die helle Oberfläche der fast vollständig gefrorenen Erde reflektierte nahezu die gesamte einfallende Sonnenenergie zurück ins All und hielt die Erde so im Eiszeitzustand gefangen; dies änderte sich erst, als die Konzentration von Kohlenstoffdioxid in der Erdatmosphäre, bedingt durch den unter dem Eis fortdauernden Vulkanismus, auf extrem hohe Werte gestiegen war. Da das CO2-Thermostat auf Veränderungen nur träge reagiert, taute die Erde nicht nur auf, sondern stürzte in der Folge für einige Jahrzehntausende in das andere Extrem eines Supertreibhauses.[130] Das Ausmaß der Vereisung ist jedoch in der Wissenschaft umstritten, weil Klimadaten aus dieser Zeit ungenau und lückenhaft sind.
Das Supertreibhaus, das vor 250 Millionen Jahren an der Perm-Trias-Grenze fast alles Leben auf der Erde auslöschte, wurde sehr wahrscheinlich von einer lang andauernden intensiven Vulkantätigkeit verursacht, die zur Entstehung des sibirischen Trapp führte. Aktuelle Isotopenuntersuchungen deuten darauf hin, dass sich die damaligen Meere innerhalb eines relativ kurzen Zeitraums um bis zu 8 K erwärmten und parallel dazu stark versauerten.[131] Während dieser und anderer Phasen extrem hoher Temperaturen enthielten die Ozeane zu großen Teilen keinen Sauerstoff. Derartige ozeanische anoxische Ereignisse wiederholten sich in der Erdgeschichte mehrfach.
Man weiß heute, dass sowohl Phasen starker Abkühlung, wie sie beispielsweise während der grande Coupure stattfand, als auch rapide Erwärmungen von Massenaussterben begleitet wurden.[132][131][129] Der Paläontologe Peter Ward behauptet sogar, dass alle bekannten Massenaussterben der Erdgeschichte mit Ausnahme des KT-Impakt durch Klimakrisen ausgelöst wurden.[133]
Das Klima der letzten 10.000 Jahre war im Vergleich zu den häufigen und starken Schwankungen der vorangegangenen Jahrhunderttausende ungewöhnlich stabil. Diese Stabilität gilt als Grundvoraussetzung für die Entwicklung und den Fortbestand der menschlichen Zivilisation.[134][135]
Zuletzt kam es während des Paläozän/Eozän-Temperaturmaximum und beim Eocene Thermal Maximum 2 zu einer schnellen und starken globalen Erwärmung, die von einem massiven Eintrag von Kohlenstoff (CO2 und/oder Methan) in die Atmosphäre verursacht wurde. Diese Epochen sind daher Gegenstand intensiver Forschungen, um daraus Erkenntnisse über mögliche Auswirkungen der laufenden menschengemachten Erwärmung zu gewinnen.[132]
Der laufende und für die kommenden Jahre erwartete Klimawandel hat möglicherweise das Ausmaß großer Klimawandel der Erdgeschichte, läuft aber mindestens um einen Faktor 20 schneller ab als alle globalen Klimawandel der letzten 65 Millionen Jahre.[2][136]
Anhand der bald zweihundert Jahre umfassenden Datenlage und Forschung kann man davon ausgehen, dass die Epoche des Pliozäns ein analoges Beispiel für die Zukunft unseres Planeten sein kann. Der Kohlenstoffdioxid-Gehalt der Atmosphäre im mittleren Pliozän wurde mit Hilfe der Isotopenuntersuchung von Δ13C ermittelt und lag damals im Bereich von 400 ppm, das entspricht der Konzentration des Jahres 2014.[137][138] Mit Hilfe von Klimaproxies sind Temperatur und Meeresspiegel der Zeit vor 5 Millionen Jahren rekonstruierbar. Zum Beginn des Pliozäns lag die globale Durchschnittstemperatur um 2 K höher als im Holozän; die globale Jahresdurchschnittstemperatur reagiert aufgrund der enormen Wärmekapazität der Weltmeere sehr träge auf Änderungen des Strahlungsantriebs und so ist sie seit Beginn der industriellen Revolution erst um 0.8 K angestiegen.
Die Erwärmung führt unter anderem zu einem Meeresspiegelanstieg. Der Meeresspiegel lag in der Mitte des Pliozäns um rund 20 Meter höher als heute.[139]
Der Intergovernmental Panel on Climate Change (IPCC) wurde 1988 vom Umweltprogramm der Vereinten Nationen (UNEP) gemeinsam mit der Weltorganisation für Meteorologie (WMO) eingerichtet und ist der 1992 abgeschlossenen Klimarahmenkonvention beigeordnet. Der IPCC fasst für seine im Abstand von etwa sechs Jahren erscheinenden Berichte die weltweiten Forschungsergebnisse auf dem Gebiet der Klimaveränderung zusammen und bildet damit den aktuellen Stand des Wissens in der Klimatologie ab.
Die Organisation wurde 2007, gemeinsam mit dem ehemaligen US-Vizepräsidenten Al Gore, mit dem Friedensnobelpreis ausgezeichnet. Der Fünfte Sachstandsbericht ist im September 2013 erschienen.
Seit der Entdeckung des Treibhauseffektes 1824 durch Jean Baptiste Joseph Fourier und 1862 von Wasserdampf und Kohlenstoffdioxid durch John Tyndall gilt die Erforschung zum Erd-Klimasystem als eine der best erforschten Wissenschaften in der Geschichte der Menschheit.[11] Seit 150 Jahren ist die wärmende Wirkung von Treibhausgasen bekannt, deren Konzentrationsanstieg in der Erdatmosphäre dann Mitte der 50er Jahre des vorigen Jahrhunderts sicher nachgewiesen werden konnte. Die seit Mitte der 1970er Jahre festgestellte, ausgeprägte und bis heute ununterbrochene Klimaerwärmung kann mit Hilfe der seitdem deutlich verbesserten Messtechnik nicht primär auf solare Einflüsse oder andere natürliche Faktoren zurückgeführt werden, da sich diese seit dieser Zeit nur minimal veränderten. Viele tausende Studien wurden seitdem veröffentlicht und die große Mehrheit dessen (etwa 97 %)[140] basieren auf dem „wissenschaftlichen Konsens zum Klimawandel“. Projektionen und Berechnungen, die vor Jahrzehnten getätigt wurden, haben sich als zuverlässig herausgestellt.[141][142][143] Die ursprünglich nur theoretischen Vorhersagen zur Wirkung des Treibhauseffekts wurden mittlerweile durch Langzeituntersuchungen direkt in der Natur auch experimentell bestätigt.[144]
Man unterscheidet in der Klimaforschung zwischen Trend und Zeitpunkt und berechnet dafür die Eintrittswahrscheinlichkeiten. Beispiele für Ereignisse, für die der genaue Zeitpunkt noch nicht ermittelt werden konnte, sind der Zeitpunkt an dem die Arktis im 21. Jahrhundert im Sommer eisfrei sein wird oder der exakte Meeresspiegelanstieg bis zum Ende des 21. Jahrhunderts. Unsicherheiten bestehen in der genauen Art, Form, Ort und der Verteilung von globalen Kipppunkten im Klimasystem und damit auch verbunden in der Kenntnis der genauen regionalen Auswirkungen der globalen Erwärmung. Die Mehrzahl der relevanten wissenschaftlichen Grundlagen gelten als sehr gut verstanden.[145]
Keine wissenschaftliche Einrichtung auf nationaler oder internationaler Ebene hat Abweichungen zu den Konsensergebnissen des Klimawandels feststellen können. Der in den IPCC-Berichten zum Ausdruck gebrachte wissenschaftliche Konsens wird von den nationalen und internationalen Wissenschaftsakademien und allen G8-Ländern ausdrücklich unterstützt.[146][6][147][148][149] Der wissenschaftliche Konsens zum Klimawandel besteht in der Feststellung, dass sich das Erd-Klimasystem erwärmt und weiter erwärmen wird. Dies wird anhand von Beobachtungen der steigenden Durchschnittstemperatur der Luft und Ozeane, großflächigem Abschmelzen von Schnee- und Eisflächen und dem Meeresspiegelanstieg ermittelt. Mit 90 % Sicherheit wird dies durch Treibhausgase, Rodungen und das Verbrennen von fossilem Treibstoff verursacht.[150][151] Die American Association for the Advancement of Science – die weltweit größte wissenschaftliche Gesellschaft – stellt dar, dass sich 97 % aller Klimatologen darüber einig sind, dass ein vom Menschen verursachter Klimawandel stattfindet und betont den zu vielen Aspekten der Klimatologie herrschenden Konsens.[152] Der Wissensstand um die mit dem Klimawandel verbundenen Folgen wird als ausreichend sicher angesehen, umfangreiche Klimaschutzmaßnahmen zu rechtfertigen.[146]
Laut einer 2014 veröffentlichten Studie besteht nur eine Wahrscheinlichkeit von 0,001 %, dass der durchschnittliche globale Temperaturanstieg in den letzten 60 Jahren, ohne vom Menschen verursachtes Treibhausgas, genauso hoch wäre.[153][154]
Der Themenkomplex der globalen Erwärmung war seit jeher Gegenstand kontroverser Diskussionen mit wechselnden Schwerpunkten. Anfang des 20. Jahrhunderts überwog die Unsicherheit, ob die theoretisch vorhergesagte Erwärmung messtechnisch überhaupt nachweisbar sein würde. Als in den USA während der 1930er Jahre erstmals ein signifikanter Temperaturanstieg in einigen Regionen registriert wurde, galt dies zwar als ein starkes Indiz für eine zunehmende Erderwärmung, gleichzeitig wurde jedoch bezweifelt, ob dieser Prozess tatsächlich auf menschlichen Einflüssen beruhte. Diese Zweifel werden von manchen klimaskeptischen Gruppierungen bis heute geäußert, und gelegentlich wird sogar in den Medien eine globale Abkühlung für die kommenden Jahrzehnte vorausgesagt, was von Klimaforschern zurückgewiesen wird.[155]
Da der direkt wärmende Effekt der Treibhausgase nur ca. ein Drittel der erwarteten Erwärmung ausmacht und der größte Teil eine Folge nicht genau quantifizierbarer Rückkopplungsvorgänge ist, ist das Ausmaß der erwarteten Erwärmung ein Aspekt der Diskussion. Ebenso ist die kommende Klimaerwärmung möglicherweise historisch einzigartig, weswegen über einzelne Folgen dieser Erwärmung teils nur spekuliert werden kann. Zwangsläufig ergeben sich damit auch Streitpunkte, wie von politischer Seite reagiert werden sollte.
Wegen der Auswirkungen auf menschliche Sicherheit, Gesundheit, Wirtschaft und Umwelt ist die globale Erwärmung mit Risiken behaftet. Einige schon heute wahrnehmbare Veränderungen wie die verringerte Schneebedeckung, der steigende Meeresspiegel oder die Gletscherschmelze gelten neben den Temperaturmessungen auch als Belege für den Klimawandel. Konsequenzen der globalen Erwärmung wirken sowohl direkt auf den Menschen als auch auf Ökosysteme. Um die vielfältigen Auswirkungen quantitativ erfassen zu können, wurde der sogenannte Klimawandelindex geschaffen.
Experten projizieren verschiedene direkte und indirekte Auswirkungen auf Hydrosphäre, Atmosphäre und Biosphäre. Im Bericht des Weltklimarats (IPCC) werden diesen Projektionen jeweils Wahrscheinlichkeiten zugeordnet. Zu den Folgen zählen Hitzewellen, besonders in den Tropen, ein Hunderte Millionen Menschen betreffender Anstieg des Meeresspiegels, und Missernten, welche die globale Ernährungssicherheit gefährden. Eine sich stark erwärmende Welt ist, so ein Weltbank-Bericht, mit erheblichen Beeinträchtigungen für den Menschen verbunden.[156]
Bedingt durch die vielfachen Rückkopplungen im Erdsystem reagiert dieses auf Einflüsse oftmals nichtlinear, d. h. Veränderungen vollziehen sich in diesen Fällen nicht kontinuierlich, sondern sprunghaft. Es bestehen eine Reihe von Kippelementen, die bei fortschreitender Erwärmung wahrscheinlich abrupt einen neuen Zustand einnehmen werden, der ab einem gewissen Punkt (Tipping Point) schwer oder gar nicht umkehrbar sein wird. Beispiele für Kippelemente sind das Abschmelzen der arktischen Eisdecke oder eine Verlangsamung der Thermohalinen Zirkulation.
Die Risiken für Ökosysteme auf einer sich erwärmenden Erde wachsen mit jedem Grad des Temperaturanstiegs. Die Risiken unterhalb einer Erwärmung von 1 K gegenüber dem vorindustriellen Wert sind vergleichsweise gering. Zwischen 1 und 2 K Erwärmung liegen auf regionaler Ebene mitunter substanzielle Risiken vor. Eine Erwärmung oberhalb von 2 K birgt erhöhte Risiken für das Aussterben zahlreicher Tier- und Pflanzenarten, deren Lebensräume nicht länger ihren Anforderungen entsprechen.[169] Bei über 2 K Temperaturanstieg droht der Kollaps von Ökosystemen und signifikante Auswirkungen auf Wasser sowie Nahrungsmittelvorräte durch Ernteausfall.[170]
Obwohl die Erwärmung der Erde durch einen kontinuierlich stattfindenden Energiezustrom verursacht wird, zeigen sich die Folgen dieses Erwärmungsprozesses nicht in kontinuierlichen Effekten, sondern meist in abrupten Ereignissen.
Wie in vielen anderen Bereichen, so führt auch der menschengemachte Klimawandel zu einer Reihe von plötzlich auftretenden Veränderungen, die oft unvorhergesehen eintreten. Beispiele sind: Plötzliches Aussterben einer Art, die - womöglich durch andere Umweltfaktoren vorbelastet - durch ein klimatisches Extremereignis eliminiert wird. Ein anderes Beispiel ist die Wirkung steigender Meeresspiegel. Diese führen nicht unmittelbar zu Überschwemmungen, sondern erst, wenn im Rahmen von z. B. Sturmfluten ein vormals ausreichender Damm überschwemmt wird. Und auch der Meeresspiegelanstieg kann sich durch nichtlineare Effekte in sehr kurzer Zeit rasch beschleunigen, wie dies in der Klimageschichte beispielsweise beim Schmelzwasserpuls 1A der Fall war. [182]
Untersuchungen von klimatischen Veränderungen in der Erdgeschichte zeigen, dass Klimawandel in der Vergangenheit nicht nur graduell und langsam abliefen, sondern bisweilen auch sehr rasch. Die Durchschnittstemperaturen veränderten sich bei diesen plötzlichen Klimaveränderungen mit einer Geschwindigkeit, die regional 10 K in 10 Jahren erreichen konnte. Nach heutigem Kenntnisstand erscheint es wahrscheinlich, dass diese schnellen Sprünge im Klimasystem auch künftig stattfinden werden, wenn bestimmte Kipppunkte überschritten werden. Das gegenwärtige Verständnis der zugrunde liegenden Prozesse reicht jedoch nicht aus, diese Ereignisse vorherzusagen. Sollte es in den kommenden Jahren oder Jahrzehnten dazu kommen, wird dies somit unerwartet und überraschend erfolgen.[183]
Das Weltwirtschaftsforum Davos stuft in seinem Bericht „Global Risks 2013“ den Klimawandel als eines der wichtigsten globalen Risiken ein: Das Wechselspiel zwischen der Belastung der wirtschaftlichen und ökologischen Systeme werde unvorhersehbare Herausforderungen für globale und nationale Widerstandsfähigkeiten darstellen.[184][185]
Verschiedene Militärstrategen und Sicherheitsexperten befürchten geopolitische Verwerfungen infolge von Klimaveränderungen, die sicherheitspolitische Risiken für die Stabilität der Weltordnung[186][187][188] und den „Weltfrieden“ bergen,[189] auch der UN-Sicherheitsrat fasste 2011 auf Initiative Deutschlands eine entsprechende Resolution.[190] Der amtierende deutsche Außenminister Frank-Walter Steinmeier bewertete im April 2015 nach Erscheinen einer zum „G7“-Außenminister-Treffen in Lübeck verfassten europäischen Studie den Klimawandel ebenfalls als „eine wachsende Herausforderung für Frieden und Stabilität“. Die Studie empfiehlt u. a. die Einrichtung einer G7-Taskforce.[191][192]
Die wirtschaftlichen Folgen der globalen Klimaerwärmung sind nach gegenwärtigen Schätzungen beträchtlich: Das Deutsche Institut für Wirtschaftsforschung schätzt, dass ohne zügig umgesetzten Klimaschutz der Klimawandel bis zum Jahr 2050 bis zu 200.000 Milliarden US-Dollar volkswirtschaftliche Kosten verursachen könnte (wobei diese Schätzung mit großen Unsicherheiten behaftet ist);[193] der 2006 veröffentlichte Stern-Report der britischen Regierung nennt an zu erwartenden Schäden durch den Klimawandel bis zum Jahr 2100 Werte zwischen 5 bis 20 % an der globalen Wirtschaftsleistung.
In einem komplexen Themenkomplex wie der globalen Erwärmung wird es ein vollständiges Verständnis aller Teilaspekte voraussichtlich niemals geben, ebenso wenig wie es bei ähnlich komplexen Themen ein vollständiges Verständnis jedes Details gibt. Die Grundlagen der den anthropogenen Klimawandel auslösenden Mechanismen gelten jedoch als verstanden.
Die Entscheidung für oder gegen Klimaschutzmaßnahmen basiert nicht auf einem „Beweis“, dass der anthropogene Klimawandel gefährliche Ausmaße annehmen wird. Vielmehr liegt ihr eine Risikoabschätzung zugrunde. Der Umweltbiologe Stephen Schneider vergleicht die Probleme einer Beweisführung für die Schädlichkeit der globalen Erwärmung mit der, die sich bei gewohnheitsmäßigem Rauchen von Tabak ergibt. So sei es bis heute unbewiesen, dass Rauchen Krebs erzeugt, auch kenne man die zugrunde liegenden Zusammenhänge nicht in allen Details. Dennoch deuteten die statistischen Befunde, also die Epidemiologie, klar auf einen engen kausalen Zusammenhang zwischen Krebs und Rauchen hin. Schneider erwähnt des Weiteren den Fall eines Patienten, bei dem im Rahmen einer Routine-Röntgenaufnahme ein verdächtiger Schatten auf der Lunge entdeckt wurde. Um herauszufinden, ob dieser Schatten der Hinweis auf einen bösartigen Tumor ist, besteht die Möglichkeit einer schmerzhaften, risikobehafteten und teuren Gewebeprobennahme (Biopsie). Alternativ könne der Patient auch warten, ob der Schatten auf dem Bild mit der Zeit größer wird, was als Beleg dafür gilt, dass ein Tumor vorliegt. Dann besteht aber die Gefahr einer Metastasierung, die die Heilungschancen drastisch verringert. Die Entscheidung für oder gegen eine Biopsie basiere wie die Entscheidung für oder gegen Klimaschutzmaßnahmen auf einer Risikobewertung. Schneider betont, dass bei einer Entscheidungsfindung, die sich auf eine Risikobetrachtung stützt, ein Beweis nicht nötig sei.[194]
Das Ausmaß der möglichen Konsequenzen der globalen Erwärmung führt zur Frage, wie diese politisch verhindert oder ihre Folgen zumindest gemildert werden können. Die Emissionsminderung aller Treibhausgase ist Hauptgegenstand der umfassenden Klimarahmenkonvention (UNFCCC) der Vereinten Nationen als der völkerrechtlich verbindlichen Regelung zum Klimaschutz. Sie wurde 1992 in New York City verabschiedet und im gleichen Jahr auf der UN-Konferenz für Umwelt und Entwicklung (UNCED) in Rio de Janeiro von den meisten Staaten unterschrieben. Mit der Rahmenkonvention geht als neu entstandenes Prinzip der Staatengemeinschaft einher, dass auf eine solche massive Bedrohung der globalen Umwelt auch ohne genaue Kenntnis des letztlichen tatsächlichen Ausmaßes reagiert werden soll. Auf der Rio-Konferenz wurde auch die Agenda 21 verabschiedet, die seitdem Grundlage für viele lokale Schutzmaßnahmen ist.
Die derzeit 194 Vertragsstaaten der Rahmenkonvention treffen sich jährlich zu UN-Klimakonferenzen. Die bekanntesten dieser Konferenzen waren 1997 im japanischen Kyōto, die als Ergebnis das Kyoto-Protokoll hervorbrachte, und 2009 in Kopenhagen.
Als Grenze von tolerablem zu „gefährlichem“ Klimawandel wird in der Klimapolitik gemeinhin eine durchschnittliche Erwärmung um 2 K gegenüber dem vorindustriellen Niveau angenommen. Das 2-Kelvin-Ziel („2-Grad-Ziel“) basiert auf der Grafik burning embers im IPCC 2001, überarbeitet 2009.[195] Da 0,7 K bereits erreicht sind, verbleiben damit noch 1,3 K. Das 2-Kelvin-Ziel wurde etwa beim G8-Gipfel im Juli 2009 anerkannt. Es ist auch Teil des Copenhagen Accord. Einzelne Staaten, besonders Mitglieder der Europäischen Union, hatten sich diesem Ziel bereits länger verschrieben. In Deutschland empfiehlt der Wissenschaftliche Beirat der Bundesregierung Globale Umweltveränderungen (WBGU) bereits seit 1994, die mittlere Erwärmung auf höchstens 2 K zu begrenzen. Das 2-Grad-Ziel ist jedoch nur als eine politische Absichtserklärung zu verstehen, da es bislang nicht in völkerrechtlich bindender Form verabschiedet worden ist.
Der Anstieg des Meeresspiegels wäre mit der 2-Kelvin-Begrenzung nicht gestoppt. Die teilweise deutlich stärkere Erwärmung über den Landflächen bringt weitere Probleme. Besonders stark zunehmende Temperaturen werden über der Arktis erwartet. Beispielsweise erklärten Indigene Völker das 2-Kelvin-Ziel für zu schwach, weil es ihre Kultur und ihre Lebensweise immer noch zerstören würde, sei es in arktischen Regionen, in kleinen Inselstaaten sowie in Wald- oder Trockengebieten.[196]
Nach einer im Jahr 2012 veröffentlichten Studie im Auftrag der Weltbank wäre eine Erwärmung um vier Grad, wie derzeit befürchtet, mit verheerenden Folgen verbunden. In den Tropen könnten Ende des Jahrhunderts die kühlsten Monate deutlich wärmer sein als die heißesten Monate der Gegenwart. Der Meeresspiegel kann bei 4 Kelvin globaler Erwärmung in diesem Jahrhundert 50 bis 100 Zentimeter steigen, und danach noch deutlich höher. Dabei ist dieser Anstieg regional unterschiedlich stark, dies hängt von Meeresströmungen und anderen Faktoren ab. Am höchsten wird das Meer den Projektionen zufolge an den Küsten von Ländern wie den Philippinen, Mexiko, Indien steigen. In der Landwirtschaft könnte dies zu großflächigen Ernteausfällen führen. Veränderungen im Wasserkreislauf können hierbei erschwerend hinzukommen, etwa wenn Dürren vorherrschen oder landwirtschaftliche Flächen überflutet werden. Betroffen seien vor allem die Armen dieser Welt, für die Entwicklung ohne Klimaschutz nach Lage der Fakten kaum möglich sei.[156]
Politische Vorgaben zum Klimaschutz müssen durch entsprechende Maßnahmen umgesetzt werden. Auf der technischen Seite existiert eine Vielzahl von Optionen zur Verminderung von Treibhausgasemissionen. So ließe sich theoretisch auch mit heutigen Mitteln ein effektiver Klimaschutz realisieren.[197] Vor allem die Kosten einer solchen Vermeidungsstrategie hemmen bislang die notwendigen Investitionen in Klimaschutztechnik, auch wenn wie oben beschrieben diese Kosten teilweise deutlich niedriger geschätzt werden, verglichen mit den ansonsten eintretenden Schäden durch den Klimawandel.
Eine verbesserte Energieeffizienz ist ein zentrales Element technischer Klimaschutzlösungen.[199][200] Nimmt die Energieeffizienz zu, kann eine Dienstleistung oder ein Produkt mit weniger Energieverbrauch als zuvor angeboten oder hergestellt werden. Das heißt beispielsweise, dass in einer Wohnung weniger geheizt werden muss, ein Kühlschrank weniger Strom benötigt oder ein Auto einen geringeren Benzinverbrauch hat. In all diesen Fällen führt die zunehmende Effizienz zu einem abnehmenden Energieverbrauch und damit zu einem verringerten Treibhausgas-Ausstoß. McKinsey berechnete zudem, dass zahlreiche Energieeffizienz-Maßnahmen gleichzeitig einen volkswirtschaftlichen Gewinn abwerfen.[201]
In einer globalen Bilanz betrachtet muss jedoch ebenfalls der Rebound-Effekt berücksichtigt werden, der dazu führt, dass eine gesteigerte Energie- bzw. Ressourceneffizienz durch eine Mehrproduktion an Produkten oder Dienstleistungen teilweise wieder ausgeglichen wird. Es wird davon ausgegangen, dass die Energieeinsparung durch Energieeffizienzmaßnahmen durch Rebound-Effekt im Schnitt um 10 % gemildert wird, wobei Werte einzelner Studien zwischen 0 und 30 % schwanken.[202]
Der Umbau des Energiesystems von fossilen auf erneuerbare Energiequellen, die sog. Energiewende, wird als ein weiterer unverzichtbarer Bestandteil effektiver Klimaschutzpolitik angesehen.[203][204] Die globalen Potenziale sind im IPCC-Bericht dargestellt.[205] Im Gegensatz zu fossilen Energieträgern wird bei der Nutzung der erneuerbaren Energien mit Ausnahme der Bioenergie kein Kohlenstoffdioxid ausgestoßen, sie sind deshalb weitgehend CO2-neutral. Der Einsatz erneuerbarer Energien bietet sowohl ökologisch als auch ökonomisch großes Potenzial, vor allem durch das weitgehende Vermeiden der mit anderen Energieformen verbundenen Folgeschäden, die als sog. Externe Kosten hohe volkswirtschaftliche Schäden verursachen.
Grundsätzlich lässt sich festhalten, dass Erneuerbare Energien verglichen mit konventionellen Energienutzungsformen eine bessere Umweltbilanz aufweisen.[206] Zwar liegt der Materialbedarf für diese Technologien höher als beim Bau von Wärmekraftwerken, die Umweltbelastung durch den höheren Materialbedarf ist jedoch gering verglichen mit den brennstoffbedingten direkten Emissionen von fossil befeuerten Kraftwerken.[207] Durch Umstellung der Energieversorgung auf ein regeneratives Energiesystem lässt sich somit die durch den Energiesektor verursachte Umweltbelastung reduzieren.[208] Ob die erhofften ökologischen Vorteile im Einzelfall realistisch sind, kann durch eine Ökobilanz festgestellt werden. So müssen bei der Biomasse-Nutzung zum Beispiel Landverbrauch, chemischer Pflanzenschutz und Reduzierung der Artenvielfalt der erwünschten CO2-Reduzierung gegenübergestellt werden.
Eine zentrale Empfehlung des IPCC ist ein globaler Kohleausstieg verbunden mit einem schnellen und grundlegenden Umbau der weltweiten Energieversorgung.[209]
Schätzungen des IPCC (2007) zufolge gehen 10 bis 12 Prozent der globalen Emissionen von Treibhausgasen auf die Landwirtschaft zurück. Nicht berücksichtigt wurden hier jedoch unter anderem die Folgen der Abholzung größerer Flächen (u. a. Regenwald) für landwirtschaftliche Zwecke. Eine Studie im Auftrag von Greenpeace geht daher von einem agrarischen Anteil von 17 bis 32 Prozent an den von Menschen verursachten Treibhausgasen aus. In Großbritannien stehen etwa 19 Prozent der Treibhausgasemissionen im Zusammenhang mit Nahrungsmitteln (Landwirtschaft, Verarbeitung, Transport, Einzelhandel, Konsum, Abfall). Etwa 50 Prozent davon gehen diesen Schätzungen zufolge auf Fleisch und Milchprodukte zurück. Das Food Climate Research Network empfiehlt daher unter anderem marktorientierte und regulative Maßnahmen zu nachhaltigerer Produktion bzw. nachhaltigerem Konsum von Lebensmitteln (z. B. CO2-emissionsabhängige Preise/Steuern).[210]
Würde der globale Fleischkonsum ab 2015 innerhalb von 40 Jahren auf weniger als ein Drittel reduziert, sänken einer Modellsimulation zufolge die Lachgas- und Methanemissionen der Landwirtschaft unter das Niveau von 1995.[211][212]
Zur Reduzierung der nahrungsmittelbezogenen Emissionen verbreitet empfohlen wird der Konsum lokal produzierter Lebensmittel. Einer US-amerikanischen Ökobilanz von Weber und Matthews (2008) zufolge liegt der Beitrag des Transports zu den Emissionen der Lebensmittelversorgung in den USA bei 11 Prozent. Der Hauptanteil (83 Prozent) entstehe bei der Produktion, weswegen die Art der konsumierten Lebensmittel den größten Einfluss habe. Besonders kritisch bezüglich der Produktion von Treibhausgasen wird der Konsum von rotem Fleisch gesehen; stattdessen sollte eher auf Milchprodukte, Geflügel, Fisch, Eier oder Gemüse zurückgegriffen werden.[213]
Für den Betrieb von fossilen Kraftwerken wird eine CO2-Abscheidung und -Speicherung (CCS) angestrebt. Zumindest für Länder wie Deutschland mit seiner begrenzten geologischen Endlagerkapazität für CO2 dürfte es sich auch bei CCS nur um eine Übergangslösung für wenige Jahrzehnte handeln.[214]
Pflanzenkohle (Biokohle, englisch biochar) besteht zu überwiegendem Anteil aus reinem Kohlenstoff und kann mit pyrolytischer Verkohlung hergestellt werden. Biokohle eingebracht ins Erdreich kann dort über Jahrtausende überdauern.[215][216][217][218][219] Man geht davon aus, dass mit nachhaltiger Pflanzenkohleerzeugung, (CO2)-, Methan (CH4)- und Distickstoffmonoxid (N2O)-Emissionen in einer Höhe von 1,8 Gigatonnen CO2-Äquivalent (=CO2e), das heißt 12 % der jährlichen, anthropogenen Treibhausemissionen kompensiert werden können. Im Verlauf eines Jahrhunderts kann eine Menge Pflanzenkohle hergestellt werden, die Gesamtemissionen in Höhe von 130 Gigatonnen CO2e entsprechen, ohne dabei Lebensmittel- und Naturschutzsicherheit zu gefährden.[220]
Technische Maßnahmen gegen die Erderwärmung wie z. B. durch Eisendüngung im Meer, um das Algenwachstum anzuregen, um auf diese Weise CO2 zu binden oder das Einbringen von Sulfate in die Stratosphäre zur Reflexion von Sonnenstrahlen, gelten mittlerweile als unbrauchbar.[221]
Individuelle Möglichkeiten für Beiträge zum Klimaschutz bestehen in Verhaltensumstellungen und verändertem Konsum mit Energieeinsparungen.[222]
Es gibt zahlreiche Maßnahmen zur CO2-Reduktion. Hierzu gehören unter anderem:
Anpassungsmaßnahmen an die globale Erwärmung beziehen sich auf bereits eingetretene bzw. künftig zu erwartende Klimaänderungen. Die damit verbundenen Schäden sollen so weit wie möglich gemindert und verträglich gestaltet werden. Andererseits wird die Nutzung regional positiver Folgemöglichkeiten des Klimawandels geprüft. Die Anpassungsfähigkeit variiert in Abhängigkeit von verschiedensten Parametern, darunter der Kenntnisstand zur örtlichen Klimaveränderung, der Entwicklungsstand und die ökonomische Leistungsfähigkeit eines Landes oder einer Gesellschaft. Insgesamt wird die Fähigkeit zur Anpassung stark durch die Vulnerabilität geprägt, speziell in sozio-ökonomischer Hinsicht. Der IPCC zählt zu den Ländern und Regionen mit besonders hoher Vulnerabilität die am wenigsten fortgeschrittenen Entwicklungsländer.
Die Palette potenzieller Anpassungsmaßnahmen reicht von rein technologischen Maßnahmen (z. B. Küstenschutz) über Verhaltensänderungen (z. B. Ernährungsverhalten, Wahl der Urlaubsziele) und betriebswirtschaftlichen Entscheidungen (z. B. veränderte Landbewirtschaftung) bis zu politischen Entscheidungen (z. B. Planungsvorschriften, Emissionsminderungsziele). Angesichts der Tatsache, dass der Klimawandel sich auf viele Sektoren einer Volkswirtschaft auswirkt, ist die Integration von Anpassung z. B. in nationale Entwicklungspläne, Armutsbekämpfungsstrategien oder sektorale Planungsprozesse eine zentrale Herausforderung.
Viele Staaten haben daher Anpassungsstrategien entwickelt. In Deutschland wurde beispielsweise 2008 die Deutsche Anpassungsstrategie an den Klimawandel verabschiedet und im Jahr 2011 mit dem Aktionsplan Anpassung mit konkreten Maßnahmen unterlegt. Zurzeit wird ein Fortschrittsbericht zur Deutschen Anpassungsstrategie erarbeitet, der u. a. die Umsetzung der Strategie evaluiert und einen Aktionsplan II enthalten wird.[224]
In Österreich wurde die nationale Anpassungsstrategie an den Klimawandel seit September 2007 im Auftrag des Lebensministeriums erarbeitet[225] und am 23. Oktober 2012 vom Ministerrat verabschiedet.[226] Am 16. April 2013 wurde von der EU Kommission eine EU-Strategie zur Anpassung an den Klimawandel vorgestellt. Bis zu diesem Datum hatten 15 EU-Mitgliedsstaaten eine eigene Anpassungsstrategie erarbeitet.[227]
In der im Jahr 1992 verabschiedeten Klimarahmenkonvention (UNFCCC), die mittlerweile von 192 Staaten ratifiziert worden ist, spielte das Thema Anpassung noch kaum eine Rolle gegenüber der Vermeidung eines gefährlichen Klimawandels (Artikel 2 der UNFCCC). Für das Kyoto-Protokoll, das 1997 vereinbart wurde und 2005 in Kraft trat, gilt das zwar ähnlich, doch wurde dort grundsätzlich der Beschluss zur Einrichtung eines speziellen UN-Anpassungsfonds („Adaptation Fund“) gefasst, um die besonders betroffenen Entwicklungsländer bei der Finanzierung von Anpassungsmaßnahmen zu unterstützen. Dazu soll auch der Green Climate Fund der Vereinten Nationen beitragen, der während der Klimakonferenz 2010 in Cancún eingerichtet wurde. Für den Fonds stellen Industrienationen Gelder bereit, damit sich Entwicklungsländer besser an den Klimawandel anpassen können.[228]
Spätestens mit dem 3. Sachstandsbericht des IPCC, der 2001 veröffentlicht wurde, hat das Verständnis für die Notwendigkeit von Anpassungsstrategien zugenommen. Betreffs der wissenschaftlichen Unterstützung für Regierungen war insbesondere das im Jahr 2006 beschlossene Nairobi-Arbeitsprogramm zu Adaptation und Vulnerabilität ein wichtiger Schritt.[229] Der Bali-Aktionsplan (Fahrplan von Bali) von 2007 behandelte Anpassung erstmals gleichgewichtig mit der Vermeidung von Emissionen, und diente als Rahmen für die anschließenden Verhandlungen zu einem neuen, umfassenden internationalen Klimaabkommen.
Die globale Erwärmung ist zunehmend auch ein Thema in Kunst, Literatur und Film.
Dargestellt wird das Thema zum Beispiel in den Katastrophenfilmen Waterworld, The Day After Tomorrow oder Welt in Angst.
Zudem gibt es verschiedene Dokumentarfilme zu dem Thema. Eine unbequeme Wahrheit gilt mit als Kernbotschaft von Nobelpreisträger Al Gore zum Klimawandel. Dokumentarischen Anspruch und teilweise polemische Inhalte hat der britische Film The Great Global Warming Swindle. Auch der schwedische Dokumentarfilm Unser Planet befasst sich unter anderem mit dem Klimawandel und beinhaltet Interviews mit verschiedenen Klimaforschern. Der US-amerikanische Dokumentarfilm Chasing Ice hat den Gletscherschwund als Folge der globalen Erwärmung zum Inhalt, und porträtiert das Extreme Ice Survey-Projekt des Naturfotografen James Balog.
Literarisch wird das Thema u. a. in den 2010 erschienenen Romanen des britischen Schriftstellers Ian McEwan („Solar“)[230][231] oder des Autorengespanns Ann-Monika Pleitgen und Ilja Bohnet („Kein Durchkommen“)[232] verarbeitet; zur Bewältigung des Klimawandels ist 2013 auch der Comic Die Große Transformation. Klima – Kriegen wir die Kurve? erschienen.[233]
Cape Farewell ist ein internationales gemeinnütziges Projekt des britischen Künstlers David Buckland. Ziel ist die Zusammenarbeit von Künstlern, Wissenschaftlern und „Kommunikatoren“ (u. a. Medienvertreter) zum Thema Klimawandel. Im Rahmen des Projekts wurden verschiedene Expeditionen zur Arktis und in die Anden durchgeführt, die u. a. filmisch, fotografisch, literarisch und musikalisch verarbeitet wurden (u. a. in den Filmen Art from the Arctic und Burning Ice).[234][235][236]
